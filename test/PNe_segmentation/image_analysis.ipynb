{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del Dataset\n",
    "Vamos a definir una clase, que tome como base la clase Dataset de Pytorch, para poder cargar todo nuestro conjunto de imágenes de uno o varios canales con su máscara correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos a cambiar el directorio de trabajo\n",
      " El directorio actual es: /mnt/netapp2/Home_FT2/home/ulc/co/ela/TFG/test/PNe_segmentation\n",
      " Contenido del directorio actual:\n",
      "\t train_models\n",
      "\t data\n",
      "\t create_dataset.ipynb\n",
      "\t data_files_1c.csv\n",
      "\t images\n",
      "\t image_analysis.ipynb\n",
      "\t masks\n",
      "\t segmentation_no_supervisada.ipynb\n",
      "\t segmentation_no_supervisada_2c.ipynb\n",
      "\t segmentation_no_supervisada_pytorch.ipynb\n",
      "\t segmentation_supervisada.ipynb\n",
      "\t dataset_info.csv\n",
      "\t data_files_1c_train.csv\n",
      "\t historico_notebooks\n",
      "\t data_files_1c_test.csv\n",
      "\t segmentation_no_supervisada_pytorch_clean.ipynb\n",
      "\t segmentation_supervisada_pytorch copy.ipynb\n",
      "\t segmentation_supervisada_pytorch.ipynb\n",
      "\t cesga\n",
      "\t segmentation_supervisada_pytorch copy 2.ipynb\n",
      "\t segmentation_supervisada_pytorch copy 3.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Vamos a cambiar el directorio de trabajo\")\n",
    "\n",
    "# Indicamos la ruta del directorio de trabajo\n",
    "route = os.getcwd() + \"/TFG/test/PNe_segmentation\"\n",
    "os.chdir(route)\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\" El directorio actual es:\", current_directory)\n",
    "\n",
    "# Listamos el contenido del directorio\n",
    "files = os.listdir(current_directory)\n",
    "print(\" Contenido del directorio actual:\")\n",
    "for file in files:\n",
    "    print(\"\\t\",file)\n",
    "    \n",
    "# Listamos el contenido del directorio de las máscaras\n",
    "# masks_directory = route+\"TFG\\\\test\\\\PNe_segmentation\\\\masks\"\n",
    "# data_directory = route+\"TFG\\\\test\\\\PNe_segmentation\\\\data\"\n",
    "## Ejecución en el CESGA Finisterrae III\n",
    "masks_directory = route+\"/masks\"\n",
    "data_directory = route+\"/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnebulae_torch.dataset import NebulaeDataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Creamos un objeto de la clase PNeDataset\n",
    "transform_x = transforms.Compose([\n",
    "                    # MinMaxNorm,\n",
    "                    # TypicalImageNorm(factor = 1, substract=0),\n",
    "                    # ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 4096),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    # transforms.ToTensor(),\n",
    "                    transforms.Lambda(lambda x: torch.from_numpy(x.copy()).unsqueeze_(0)),\n",
    "                    # CustomPad(target_size = (1984, 1984), fill_min=True, tensor_type=torch.Tensor.float)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Lambda(lambda x: torch.Tensor.int(x)),\n",
    "                    # CustomPad(target_size = (1984, 1984), fill = 0, tensor_type=torch.Tensor.int)\n",
    "                    ])\n",
    "\n",
    "df_train = pd.read_csv(\"data_files_1c_train_correct.csv\")\n",
    "dataset_train = NebulaeDataset(data_directory, masks_directory, df_train, transform = (transform_x, transform_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4574.5986)\n",
      "tensor(365.0783)\n",
      "tensor(279.1983)\n",
      "tensor(1208.6595)\n",
      "tensor(3825.2434)\n",
      "tensor(7432.4995)\n",
      "tensor(977.3033)\n",
      "tensor(1752.2561)\n",
      "tensor(626.5923)\n",
      "tensor(1735.3855)\n",
      "tensor(244.0661)\n",
      "tensor(733.6297)\n",
      "tensor(188.1891)\n",
      "tensor(794.0305)\n",
      "tensor(5461.5781)\n",
      "tensor(589.0709)\n",
      "tensor(3324.)\n",
      "tensor(10123.4336)\n",
      "tensor(4850.9463)\n",
      "tensor(298.4151)\n",
      "tensor(3765.7341)\n",
      "tensor(69677.0547)\n",
      "tensor(238.7206)\n",
      "tensor(617.5674)\n",
      "tensor(1554.6730)\n",
      "tensor(2776.8040)\n",
      "tensor(1081.0856)\n",
      "tensor(16571.4668)\n",
      "tensor(0.9997)\n",
      "tensor(2164.5503)\n",
      "tensor(366.0248)\n",
      "tensor(3965.0193)\n",
      "tensor(166.2244)\n",
      "tensor(792.7939)\n",
      "tensor(4685.3159)\n",
      "tensor(1976.6223)\n",
      "tensor(11650.4160)\n",
      "tensor(550.4119)\n",
      "tensor(1196.4901)\n",
      "tensor(62289.0117)\n",
      "tensor(442.4381)\n",
      "tensor(125873.7500)\n",
      "tensor(1083.5076)\n",
      "tensor(2157.9941)\n",
      "tensor(3283.0576)\n",
      "tensor(71253.5859)\n",
      "El archivo es: 45\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset_train)):\n",
    "    print(dataset_train[i][0].max())\n",
    "    if dataset_train[i][0].max() == 71253.5859:\n",
    "        print(\"El archivo es:\", i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: tensor(-88.9933)\n",
      "Max value: tensor(125873.7500)\n"
     ]
    }
   ],
   "source": [
    "min_values = []\n",
    "max_values = []\n",
    "\n",
    "for i in range(len(dataset_train)):\n",
    "    min_values.append(dataset_train[i][0].min())\n",
    "    max_values.append(dataset_train[i][0].max())\n",
    "\n",
    "print(\"Min value:\", min(min_values))\n",
    "print(\"Max value:\", max(max_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
