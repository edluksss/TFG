{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de segmentación con el Catálogo Morfológico de Nebulosas Planetarias del IAC (NO SUPERVISADO)\n",
    "En este documento vamos a probar las técnicas comentadas por Diego Cantorna en el documento de astrogestem (disponible en la carpeta astrosegstem de este mismo repositorio) y vamos a añadir ciertas técnicas y mejoras. Todas las técnicas testeadas en este Jupyter Notebook son de aprendizaje no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del Dataset\n",
    "Vamos a definir una clase, que tome como base la clase Dataset de Pytorch, para poder cargar todo nuestro conjunto de imágenes de uno o varios canales con su máscara correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Vamos a cambiar el directorio de trabajo\")\n",
    "\n",
    "# Indicamos la ruta del directorio de trabajo\n",
    "route = os.getcwd()+ \"/TFG/test/PNe_segmentation\"\n",
    "os.chdir(route)\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\" El directorio actual es:\", current_directory)\n",
    "\n",
    "# Listamos el contenido del directorio\n",
    "files = os.listdir(current_directory)\n",
    "print(\" Contenido del directorio actual:\")\n",
    "for file in files:\n",
    "    print(\"\\t\",file)\n",
    "    \n",
    "# Listamos el contenido del directorio de las máscaras\n",
    "# masks_directory = route+\"TFG\\\\test\\\\PNe_segmentation\\\\masks\"\n",
    "# data_directory = route+\"TFG\\\\test\\\\PNe_segmentation\\\\data\"\n",
    "## Ejecución en el CESGA Finisterrae III\n",
    "masks_directory = route+\"/masks\"\n",
    "data_directory = route+\"/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import random as rd\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "MinMaxNorm = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "class NebulaeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_path, mask_path, dataframe, rsize = None, transform = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_path = image_path  # Ruta a las imágenes\n",
    "        self.mask_path = mask_path  # Ruta a las máscaras\n",
    "        \n",
    "        # Cargar los nombres de las imágenes y máscaras desde el dataframe\n",
    "        self.data_dict = dataframe.set_index('name').to_dict(orient='index')\n",
    "\n",
    "        # Filtrar las rutas de archivo según los nombres en el dataframe\n",
    "        self.img_files = [os.path.join(self.image_path, files['h']) for files in self.data_dict.values()]\n",
    "        self.mask_files = [os.path.join(self.mask_path, files['mask']) for files in self.data_dict.values()]\n",
    "        self.names = list(self.data_dict.keys())  # Nombres de las imágenes y máscaras\n",
    "                \n",
    "        self.rsize = rsize  # Size to use in default Resize transform\n",
    "        self.transform = transform\n",
    "\n",
    "    # Returns both the image and the mask\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_files[index]\n",
    "        mask_path = self.mask_files[index]\n",
    "        \n",
    "        image = np.flip(fits.getdata(img_path, memmap=False).astype(np.float32), axis=0)\n",
    "        mask = plt.imread(mask_path)\n",
    "        \n",
    "        # Take only the first channel. CHANGE THIS IF WE ARE GOING TO WORK WITH NUMEROUS CHANNELS\n",
    "        if len(mask.shape) > 2:\n",
    "            mask = mask[:,:,0]\n",
    "        if len(image.shape) > 2:\n",
    "            image = image[:,:,0]\n",
    "        \n",
    "        # Apply the defined transformations to both image and mask\n",
    "        if self.transform is not None:\n",
    "            seed = np.random.randint(2147483647) # make a seed with numpy generator \n",
    "            rd.seed(seed) # apply this seed to image transforms\n",
    "            torch.manual_seed(seed)\n",
    "            if type(self.transform) == tuple:\n",
    "                image = self.transform[0](image)\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "            rd.seed(seed) # apply the same seed to mask transforms\n",
    "            torch.manual_seed(seed) \n",
    "            if type(self.transform) == tuple:\n",
    "                mask = self.transform[1](mask)\n",
    "            else:\n",
    "                mask = self.transform(mask)\n",
    "        else:\n",
    "            if self.rsize is not None:\n",
    "                t = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(self.rsize, interpolation= InterpolationMode.NEAREST)\n",
    "                    ])\n",
    "            else:\n",
    "                t = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "            image = t(image)\n",
    "            mask = t(mask)\n",
    "        \n",
    "        return image, mask.int()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def different_shapes(self):\n",
    "        shapes = set([tuple(self[i][0].permute(2,1,0).shape) for i in range(len(self))])\n",
    "        return list(shapes)\n",
    "    \n",
    "    def plot(self, index, plot_image = True, plot_mask = False):\n",
    "        \"\"\"\n",
    "        Muestra una imagen y/o máscara aleatoria del lote.\n",
    "        \n",
    "        Parámetros:\n",
    "        index (int): Índice del lote.\n",
    "        plot_image (bool, opcional): Si es True, muestra la imagen. Por defecto es True.\n",
    "        plot_mask (bool, opcional): Si es True, muestra la máscara. Por defecto es False.\n",
    "        \"\"\"\n",
    "        image, mask = self[index]\n",
    "        image = image.permute(1,2,0)\n",
    "        mask = mask.permute(1,2,0)\n",
    "        name = self.names[index]\n",
    "        \n",
    "        if plot_image:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            fig.suptitle(f\"Canales de la nebulosa {name}\", fontweight = 'bold', fontsize = 14)\n",
    "            ax.imshow(image, cmap = \"gray\")\n",
    "            ax.set_title(f\"Canal H\")\n",
    "            fig.show()\n",
    "        if plot_mask:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            fig.suptitle(f\"Máscara de la nebulosa {name}\", fontweight = 'bold', fontsize = 14)\n",
    "            ax.imshow(mask, cmap = \"gray\")\n",
    "            fig.show()\n",
    "            \n",
    "    def different_shapes(self):\n",
    "        shapes = set([tuple(self[i][0].permute(2,1,0).shape) for i in range(len(self))])\n",
    "        return list(shapes)\n",
    "    \n",
    "    def bg_obj_proportions(self):\n",
    "        proportions = []\n",
    "        for i in range(len(self)):\n",
    "            mask = self[i][1].numpy()\n",
    "            bg = np.sum(mask == 0)\n",
    "            obj = np.sum(mask == 1)\n",
    "            proportions.append(obj/(bg+obj))\n",
    "        return proportions\n",
    "    \n",
    "    def contrast_differences(self, radius = None):\n",
    "        contrasts = []\n",
    "        if radius is not None:\n",
    "            for i in range(len(self)):\n",
    "                image = self[i][0].numpy()\n",
    "                mask = self[i][1].numpy()\n",
    "                bg = image[mask == 0]\n",
    "                obj = image[mask == 1]\n",
    "                contrasts.append(np.mean(obj) - np.mean(bg))\n",
    "        else:\n",
    "            for i in range(len(self)):\n",
    "                image = self[i][0].numpy()\n",
    "                mask = self[i][1].numpy()\n",
    "                \n",
    "                bg = image[mask == 0]\n",
    "                obj = image[mask == 1]\n",
    "                contrasts.append(np.mean(obj) - np.mean(bg))\n",
    "        return contrasts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora deberíamos de ser capaces de poder cargar todas las imágenes, como tensores de PyTorch, de nuestro csv como un Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(99, plot_image = True, plot_mask = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de las imágenes\n",
    "Para la segmentación de las imágenes, vamos a probar diferentes algoritmos/técnicas propuestas por Diego Cantorna en el notebook de 'astrosegstem', pero para un mayor conjunto de datos para poder evaluarlas y verificar sus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de resultados\n",
    "Para evaluar el resultado de las técnicas de segmentación se pueden emplear distintas métricas.\n",
    "\n",
    "Algunas de las métricas más utilizadas son la precisión, accuracy y recall, que junto al análisis de la matriz de confusión son las más utilizadas para cualquier problema de procesamiento de imágenes. A estas también se unen:\n",
    "- **Coeficiente de Dice** (Dice Similarity Coefficient): Mide la similitud entre la segmentación predicha y la segmentación de referencia. Valores más cercanos a 1 indican una mejor superposición. Para un problema de segmentación binaria como el nuestro, el F1-Score y el Dice son equivalentes.\n",
    "- **Índice de Jaccard** (Jaccard Index o Intersection over Union, IoU): Calcula la intersección entre la segmentación predicha y la segmentación de referencia dividida por su unión. También mide la superposición.\n",
    "las cuales son métricas básicas y esenciales en los problemas de segmentación.\n",
    "\n",
    "Vamos a utilizar todas estas métricas para evaluar nuestras técnicas de segmentación.\n",
    "\n",
    "Vamos a dar mayor prioridad a la hora de evaluar al F1-Score (equivalente al Dice), al IoU y a la precisión, debido a que queremos extraer la silueta aunque no sea de una manera exacta. Métricas como el accuracy en este tipo de problemas no son muy representativas dado a que si el 90 por ciento de la imagen es fondo y nuestra técnica predice como máscara todo 0s (es decir, todo negro) nos va a devolver un 90 por ciento de accuracy pero realmente no nos estaría aportando ninguna información de valor. El recall sería una métrica más idónea si no nos quisiésemos saltar ningún píxel que tenemos que predecir como positivo, aunque diésemos algún falso positivo (métrica muy observada en segmentación de imagen médica por ejemplo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas de agrupamiento de datos\n",
    "Las técnicas de agrupamiento (clustering) tratan de encontrar una partición de un\n",
    "conjunto de datos de forma que los elementos de un mismo grupo sean más similares\n",
    "que los elementos de grupos distintos. Esto permite resumir un conjunto de datos,\n",
    "y puede facilitar algunos procesos de visualización o análisis posteriores con otras\n",
    "técnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from skimage import morphology, exposure\n",
    "from scipy import ndimage\n",
    "import skfuzzy as fuzz\n",
    "\n",
    "class ApplyKMeans:\n",
    "    def __init__(self, concat = False, **kwargs):\n",
    "        self.concat = concat\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "            \n",
    "        im_array = im.reshape(-1, 1)\n",
    "    \n",
    "        kmeans = KMeans(**self.kwargs).fit(im_array)  # Entrenar el modelo K-Means\n",
    "        \n",
    "        # Obtener la imagen segmentada aplicando el algoritmo a cada píxel de la imagen\n",
    "        im_segm_array = kmeans.predict(im_array)\n",
    "\n",
    "        # Reemplazar los índices de los clústeres por los centroides de los clústeres\n",
    "        im_segm_array = np.array([kmeans.cluster_centers_[i] for i in im_segm_array])\n",
    "\n",
    "        # Cambiar las dimensiones de los datos segmentados para que se correspondan con la imagen inicial\n",
    "        im_segm = im_segm_array.reshape(im.shape[0], im.shape[1], 1)\n",
    "        \n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            return np.concatenate((im_orig, im_segm), axis=2)\n",
    "        else:\n",
    "            return im_segm\n",
    "\n",
    "class ApplyFCM:\n",
    "    def __init__(self, concat = False, **kwargs):\n",
    "        self.concat = concat\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "            \n",
    "        im_array = im.reshape(1, -1)\n",
    "\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data=im_array, **self.kwargs)  # Aplicar el algoritmo FCM\n",
    "        \n",
    "        # Asociar a cada píxel el cluster para el que tiene una mayor pertenencia\n",
    "        clusters_array = np.argmax(u, axis=0)\n",
    "        maximos = np.max(u, axis=0)\n",
    "\n",
    "        # Reemplazar los índices de los clústeres por los centroides de los clústeres\n",
    "        im_segm_array = np.array([cntr[i] for i in clusters_array])\n",
    "\n",
    "        # Cambiar las dimensiones de los datos segmentados para que se correspondan con la imagen inicial\n",
    "        im_segm = im_segm_array.reshape(im.shape[0], im.shape[1], 1)\n",
    "        \n",
    "        maximos = maximos.reshape(im.shape[0], im.shape[1], 1)\n",
    "        im_segm = np.concatenate((maximos, im_segm), axis=2)\n",
    "            \n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            return np.concatenate((im_orig, im_segm), axis=2)\n",
    "        else:\n",
    "            return im_segm\n",
    "\n",
    "class ApplyMorphology:\n",
    "    def __init__(self, operation = morphology.opening, concat = False, **kwargs):\n",
    "        self.concat = concat\n",
    "        self.operation = operation\n",
    "        self.kwargs = kwargs\n",
    "        if operation == morphology.binary_opening or operation == morphology.binary_closing:\n",
    "            self.mode = \"star_background\"\n",
    "        else:\n",
    "            self.mode = \"nebulae\"\n",
    "    \n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "        \n",
    "        if self.mode == \"nebulae\":\n",
    "            im_filt = self.operation(im, **self.kwargs)\n",
    "        else:\n",
    "            im_preproc = np.copy(im)\n",
    "            im_filt = ndimage.gaussian_filter(im, sigma=3)\n",
    "            im_filt[im == 0] = 0\n",
    "\n",
    "            im_zonas_claras_peq = im > (im_filt + np.std(im))\n",
    "\n",
    "            im_zonas_claras_peq = self.operation(im_zonas_claras_peq, **self.kwargs)\n",
    "                \n",
    "            im_preproc = (im_preproc - np.min(im_preproc))\n",
    "            im_preproc[im_zonas_claras_peq] = 0\n",
    "            \n",
    "            im_filt = im_preproc\n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            im_filt = np.expand_dims(im_filt, axis=2)\n",
    "            return np.concatenate((im_orig, im_filt), axis=2)\n",
    "        else:\n",
    "            return self.operation(im, **self.kwargs)\n",
    "\n",
    "class ApplyIntensityTransformation:\n",
    "    def __init__(self, transformation = exposure.rescale_intensity, concat = False, **kwargs):\n",
    "        self.transformation = transformation\n",
    "        self.kwargs = kwargs\n",
    "        self.concat = concat\n",
    "        self.in_range = None\n",
    "        self.kernel_size = None\n",
    "        \n",
    "        if \"in_range\" in self.kwargs:\n",
    "            self.in_range = self.kwargs[\"in_range\"]\n",
    "        \n",
    "        if \"kernel_size\" in self.kwargs:\n",
    "            self.kernel_size = self.kwargs[\"kernel_size\"]\n",
    "    \n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "        \n",
    "        if self.in_range is not None:\n",
    "            self.kwargs[\"in_range\"] = (im.max() * self.in_range[0], im.max() * self.in_range[1])\n",
    "        \n",
    "        # self.kwargs[\"in_range\"] = (im.min(), im.max()) # Linea para realizar un reescalado de la intensidad de la imagen lineal\n",
    "        \n",
    "        if self.kernel_size is not None:\n",
    "            self.kwargs[\"kernel_size\"] = im.shape[0] // self.kernel_size\n",
    "            \n",
    "        im_trans = self.transformation(im, **self.kwargs)\n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            im_trans = np.expand_dims(im_trans, axis=2)\n",
    "            return np.concatenate((im_orig, im_trans), axis=2)\n",
    "        else:\n",
    "            return self.transformation(im, **self.kwargs)\n",
    "        \n",
    "class ApplyFilter:\n",
    "    def __init__(self, filter = ndimage.gaussian_filter, concat = False, **kwargs):\n",
    "        self.filter = filter\n",
    "        self.kwargs = kwargs\n",
    "        self.concat = concat\n",
    "    \n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "        \n",
    "        im_filt = self.filter(im, **self.kwargs)\n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            im_filt = np.expand_dims(im_filt, axis=2)\n",
    "            return np.concatenate((im_orig, im_filt), axis=2)\n",
    "        else:\n",
    "            return self.filter(im, **self.kwargs)\n",
    "        \n",
    "class CustomPad():\n",
    "    def __init__(self, target_size = (1056, 1536), fill = 0):\n",
    "        self.target_size = target_size\n",
    "        self.fill = fill\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        # Get the size of the input image\n",
    "        width, height = image.shape[2], image.shape[1]\n",
    "\n",
    "        # Compute the size of the padding\n",
    "        pad_width = self.target_size[1] - width\n",
    "        pad_height = self.target_size[0] - height\n",
    "\n",
    "        # Compute the padding\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "\n",
    "        # Apply the padding\n",
    "        return transforms.functional.pad(image, (pad_left, pad_top, pad_right, pad_bottom), fill = self.fill)\n",
    "    \n",
    "    \n",
    "def plot_all(image, mask, **kwargs):\n",
    "        image = image.permute(1,2,0)\n",
    "        mask = mask.permute(1,2,0)\n",
    "        \n",
    "        n_channels = image.shape[2]\n",
    "        fig, ax = plt.subplots(1, n_channels + 1, figsize=(5 * n_channels, 5))\n",
    "        # fig.suptitle(f\"Canales de la nebulosa y máscara\", fontweight = 'bold', fontsize = 14)\n",
    "        for i in range(n_channels):\n",
    "            ax[i].imshow(image[:,:,i]*255, **kwargs)\n",
    "            ax[i].set_title(f\"Canal {i}\")\n",
    "            \n",
    "        ax[n_channels].imshow(mask, cmap = \"gray\")\n",
    "        ax[n_channels].set_title(f\"Máscara\")\n",
    "        fig.show()\n",
    "    \n",
    "def filter_cluster(image, min_background_percentage=0.90, mask_probs = None):\n",
    "    \"\"\"\n",
    "    Filtra los clusters de una imagen binarizada para obtener el fondo.\n",
    "    \n",
    "    Parámetros:\n",
    "    image (torch.Tensor): Imagen binarizada.\n",
    "    min_background_percentage (float, opcional): Porcentaje mínimo de píxeles de fondo. Por defecto es 0.90.\n",
    "    \n",
    "    Retorna:\n",
    "    torch.Tensor: Imagen binarizada con el fondo.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage:\n",
    "            break\n",
    "        \n",
    "        background = new_background\n",
    "    \n",
    "    if mask_probs is not None:\n",
    "        background = background * mask_probs\n",
    "        \n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "Vamos a comenzar por la técnica más básica (y en la que se basan la mayoría), K-Means.\n",
    "\n",
    "Para aplicar el algoritmo se selecciona el número de grupos a utilizar y un prototipo (elemento representativo) de cada grupo. A continuación se realiza un proceso iterativo en el que se van asignando datos al grupo más próximo, se recalcula el prototipo de cada grupo, y se repite el proceso hasta que se estabiliza. \n",
    "\n",
    "En este caso aplicaremos el algoritmo a los píxeles de imágenes de niveles de gris, por lo que el prototipo de cada grupo será el valor de un píxel. El número de grupos podemos establecerlo manualmente, realizando pruebas con distintos valores. Existen algoritmos más complejos que tratan de automatizar el proceso, pero es interesante familiarizarse inicialmente con las versiones más simples de los algoritmos, para centrar el estudio en los aspectos fundamentales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las pruebas con el K-Means van a ser realizadas con un modelo K-Means para cada imagen (para ambos canales) normalizando los datos entre 0 y 1 y dejandolos con sus valores reales (Demostrado que funciona exactamente igual, solo se realizará con los datos normalizados para que todas las imágenes se muevan en el mismo rango de valores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from sklearn.cluster import KMeans\n",
    "    \n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyKMeans(concat=False, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "dataset.plot(40, plot_image = True, plot_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "rd.seed(42)\n",
    "random_indexs = rd.sample(range(len(dataset)), 3)\n",
    "for index in random_indexs:\n",
    "    plot_all(*dataset[index], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Filtrado de los clusters (porcentaje de fondo)***\n",
    "\n",
    "Vamos a realizar un filtrado de los cluster de la siguiente manera:\n",
    "\n",
    "1. Tomamos el cluster con el valor de centroide más bajo y lo tomamos como fondo\n",
    "    1. Si el cluster considerado como fondo es demasiado pequeño, nos fijamos en el siguiente cluster con el centroide más bajo\n",
    "    2. Si el siguiente cluster con los valores de centroide más bajo es muy pequeño nos fijamos en el para considerarlo también como fondo. (Esta parte finalmente no le veo mucho sentido implementarlo, debido a que es practicamente lo mismo que variar el umbral general)\n",
    "2. El resto que no se ha considerado como fondo se considera como nebulosa consiguiendo una primera aproximación a la segmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "# Celda para observar las proporciones de fondo máximas, mínimas y medias de las imágenes para decidir el umbral de segmentación\n",
    "nebulae_proportions = dataset.bg_obj_proportions()\n",
    "print(f\"Mean background proportion: {1-np.mean(nebulae_proportions):.4f}\\nMax background proportion: {1-min(nebulae_proportions):.4f}\\nMin background proportion: {1-max(nebulae_proportions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda de código donde se realizan algunas pruebas para comprobar los resultados de la segmentación\n",
    "# Más adelante se implementa este código en una función que se puede llamar desde el script principal\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[1]\n",
    "    \n",
    "    min_background_percentage = 0.925\n",
    "    # min_add_background_percentage = 0.2\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "        #     if add_background.sum() / add_background.numel() > min_add_background_percentage:\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         continue\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Filtrado de los clusters (diferencia de contraste)***\n",
    "\n",
    "Otro tipo de filtrado de clusters que vamos a probar va a ser el siguiente:\n",
    "- 1er cluster se considera como fondo\n",
    "- Siguiente cluster se calcula la diferencia de contraste entre x píxeles hacia el interior y x hacia el exterior.\n",
    "- Si la diferencia entra dentro de unos umbrales definidos (mediante el análisis anterior) se para de procesar clusters, sino se sigue procesando el siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, binary_dilation, disk, reconstruction, binary_closing\n",
    "from skimage import measure\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "image, mask = dataset[34]\n",
    "\n",
    "mask_wo_holes = binary_closing(mask[0].numpy(), footprint=disk(image.shape[1]*0.1))\n",
    "mask_erosion = binary_erosion(mask_wo_holes, footprint=disk(image.shape[1]*0.1))\n",
    "\n",
    "mask_dilation = binary_dilation(mask[0].numpy(), disk(image.shape[1]*0.1))\n",
    "\n",
    "contour_mask = measure.find_contours(mask[0].numpy())\n",
    "contour_mask_erosion = measure.find_contours(mask_erosion)\n",
    "contour_mask_dilation = measure.find_contours(mask_dilation)\n",
    "\n",
    "fig, axis = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "axis[0].imshow(mask.permute(1,2,0), cmap = \"gray\")\n",
    "for contour in contour_mask:\n",
    "    axis[0].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "axis[0].set_title(\"Original mask\")\n",
    "\n",
    "axis[1].imshow(mask_erosion, cmap = \"gray\")\n",
    "for contour in contour_mask_erosion:\n",
    "    axis[1].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "axis[1].set_title(\"Erosion mask\")\n",
    "\n",
    "axis[2].imshow(mask_dilation, cmap = \"gray\")\n",
    "for contour in contour_mask_dilation:\n",
    "    axis[2].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "axis[2].set_title(\"Dilation mask\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, binary_dilation, disk, reconstruction, binary_closing\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "image, mask = dataset[34]\n",
    "\n",
    "mask_wo_holes = binary_closing(mask[0].numpy(), footprint=disk(image.shape[1]*0.025))\n",
    "mask_erosion = binary_erosion(mask_wo_holes, footprint=disk(image.shape[1]*0.025))\n",
    "\n",
    "mask_dilation = binary_dilation(mask[0].numpy(), disk(image.shape[1]*0.025))\n",
    "\n",
    "contour_mask = measure.find_contours(mask[0].numpy())\n",
    "contour_mask_erosion = measure.find_contours(mask_erosion)\n",
    "contour_mask_dilation = measure.find_contours(mask_dilation)\n",
    "\n",
    "fig, axis = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "# Crear una imagen en blanco del mismo tamaño que la máscara\n",
    "blank_image = np.zeros_like(mask[0].numpy())\n",
    "\n",
    "# Dibujar los contornos en la imagen en blanco\n",
    "for contour in contour_mask:\n",
    "    for point in contour:\n",
    "        blank_image[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "axis[0].imshow(blank_image, cmap=\"gray\")\n",
    "axis[0].set_title(\"Original mask contour\")\n",
    "\n",
    "# Repetir el proceso para la máscara erosionada\n",
    "blank_image_erosion = np.zeros_like(mask_erosion)\n",
    "\n",
    "for contour in contour_mask_erosion:\n",
    "    for point in contour:\n",
    "        blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "axis[1].imshow(blank_image_erosion, cmap=\"gray\")\n",
    "axis[1].set_title(\"Erosion mask contour\")\n",
    "\n",
    "# Repetir el proceso para la máscara dilatada\n",
    "blank_image_dilation = np.zeros_like(mask_dilation)\n",
    "\n",
    "for contour in contour_mask_dilation:\n",
    "    for point in contour:\n",
    "        blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "axis[2].imshow(blank_image_dilation, cmap=\"gray\")\n",
    "axis[2].set_title(\"Dilation mask contour\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya sabemos como extraer una máscara del contorno de x píxeles hacia el interior de la máscara y hacia el exterior. Vamos a proceder a realizar el calculo de la diferencia de la siguiente manera:\n",
    "\n",
    "$$\\text{{media\\_diferencia\\_contraste}} = \\frac{{\\sum(\\text{{pixeles\\_interior}})}}{{\\text{{count}}(\\text{{pixeles\\_interior}})}} - \\frac{{\\sum(\\text{{pixeles\\_exterior}})}}{{\\text{{count}}(\\text{{pixeles\\_exterior}})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import binary_erosion, binary_dilation, disk, reconstruction, binary_closing\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "# Para esta prueba puede ser interesante trabajar siempre con las imágenes después de aplicar una adaptación del histograma\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyIntensityTransformation(concat=True, transformation=exposure.equalize_hist, nbins = 2048),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "# Descomentar las siguientes dos líneas para trabajar con las imágenes originales\n",
    "# df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "image, mask = dataset[31]\n",
    "\n",
    "mask_wo_holes = binary_closing(mask[0].numpy(), footprint=disk(image.shape[1]*0.025))\n",
    "mask_erosion = binary_erosion(mask_wo_holes, footprint=disk(image.shape[1]*0.025))\n",
    "\n",
    "mask_dilation = binary_dilation(mask[0].numpy(), disk(image.shape[1]*0.025))\n",
    "\n",
    "contour_mask = measure.find_contours(mask[0].numpy())\n",
    "contour_mask_erosion = measure.find_contours(mask_erosion)\n",
    "contour_mask_dilation = measure.find_contours(mask_dilation)\n",
    "\n",
    "# Repetir el proceso para la máscara erosionada\n",
    "blank_image_erosion = np.zeros_like(mask_erosion, dtype=np.uint8)\n",
    "\n",
    "for contour in contour_mask_erosion:\n",
    "    for point in contour:\n",
    "        blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "# Repetir el proceso para la máscara dilatada\n",
    "blank_image_dilation = np.zeros_like(mask_dilation, dtype=np.uint8)\n",
    "\n",
    "for contour in contour_mask_dilation:\n",
    "    for point in contour:\n",
    "        blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "        \n",
    "# Calcular la diferencia entre los contornos erosionados y dilatados\n",
    "contour_values_dilation = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_dilation\n",
    "contour_values_erosion = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_erosion\n",
    "\n",
    "fig, axis = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axis[0].imshow(image.permute(1,2,0).numpy()[:,:,-1], cmap=\"gray\")\n",
    "axis[0].set_title(\"Original image\")\n",
    "\n",
    "axis[1].imshow(contour_values_erosion, cmap=\"gray\")\n",
    "axis[1].set_title(\"Erosion\")\n",
    "axis[2].imshow(contour_values_dilation, cmap=\"gray\")\n",
    "axis[2].set_title(\"Dilation\")\n",
    "\n",
    "bp_erosion = contour_values_erosion.flatten()[contour_values_erosion.flatten()!=0]\n",
    "bp_dilation = contour_values_dilation.flatten()[contour_values_dilation.flatten()!=0]\n",
    "\n",
    "# Calcular la media y la desviación típica de los valores de contraste\n",
    "media_erosion = np.mean(bp_erosion)\n",
    "std_erosion = np.std(bp_erosion)\n",
    "media_dilation = np.mean(bp_dilation)\n",
    "std_dilation = np.std(bp_dilation)\n",
    "\n",
    "# Crear el gráfico de cajas\n",
    "bp = axis[3].boxplot([bp_erosion, bp_dilation], labels=[\"Erosion\", \"Dilation\"])\n",
    "axis[3].set_title(\"Contrast values\")\n",
    "\n",
    "# Agregar las líneas de la media y la desviación típica al gráfico de cajas\n",
    "for i, line in enumerate(bp['medians']):\n",
    "    x, y = line.get_xydata()[1]\n",
    "    if i == 0:\n",
    "        text = f'Media = {media_erosion:.6f}\\nSTD = {std_erosion:.6f}'\n",
    "    else:\n",
    "        text = f'Media = {media_dilation:.6f}\\nSTD = {std_dilation:.6f}'\n",
    "    axis[3].text(x, y, text, horizontalalignment ='center', verticalalignment='bottom') \n",
    "\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean erosion contrast: 0.854969 +/- 0.047778\n",
      "Mean dilation contrast: 0.693031 +/- 0.063594\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import binary_erosion, binary_dilation, disk, reconstruction, binary_closing\n",
    "from skimage import measure\n",
    "import numpy as np\n",
    "\n",
    "# Para esta prueba puede ser interesante trabajar siempre con las imágenes después de aplicar una adaptación del histograma\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 2048),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    # ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "# Descomentar las siguientes dos líneas para trabajar con las imágenes originales\n",
    "# df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "means_erosion = []\n",
    "stds_erosion = []\n",
    "means_dilation = []\n",
    "stds_dilation = []\n",
    "\n",
    "for i in range(0, len(dataset)):\n",
    "\n",
    "    image, mask = dataset[i]\n",
    "\n",
    "    mask_wo_holes = binary_closing(mask[0].numpy(), footprint=disk(image.shape[1]*0.025))\n",
    "    mask_erosion = binary_erosion(mask_wo_holes, footprint=disk(image.shape[1]*0.025))\n",
    "\n",
    "    mask_dilation = binary_dilation(mask[0].numpy(), disk(image.shape[1]*0.025))\n",
    "\n",
    "    contour_mask = measure.find_contours(mask[0].numpy())\n",
    "    contour_mask_erosion = measure.find_contours(mask_erosion)\n",
    "    contour_mask_dilation = measure.find_contours(mask_dilation)\n",
    "\n",
    "    # Repetir el proceso para la máscara erosionada\n",
    "    blank_image_erosion = np.zeros_like(mask_erosion, dtype=np.uint8)\n",
    "\n",
    "    for contour in contour_mask_erosion:\n",
    "        for point in contour:\n",
    "            blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "    # Repetir el proceso para la máscara dilatada\n",
    "    blank_image_dilation = np.zeros_like(mask_dilation, dtype=np.uint8)\n",
    "\n",
    "    for contour in contour_mask_dilation:\n",
    "        for point in contour:\n",
    "            blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "            \n",
    "    # Calcular la diferencia entre los contornos erosionados y dilatados\n",
    "    contour_values_dilation = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_dilation\n",
    "    contour_values_erosion = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_erosion\n",
    "\n",
    "    bp_erosion = contour_values_erosion.flatten()[contour_values_erosion.flatten()!=0]\n",
    "    bp_dilation = contour_values_dilation.flatten()[contour_values_dilation.flatten()!=0]\n",
    "\n",
    "    # Calcular la media y la desviación típica de los valores de contraste\n",
    "    means_erosion.append(np.mean(bp_erosion))\n",
    "    stds_erosion.append(np.std(bp_erosion))\n",
    "    means_dilation.append(np.mean(bp_dilation))\n",
    "    stds_dilation.append(np.std(bp_dilation))\n",
    "\n",
    "print(f\"Mean erosion contrast: {np.mean(means_erosion):.6f} +/- {np.mean(stds_erosion):.6f}\")\n",
    "print(f\"Mean dilation contrast: {np.mean(means_dilation):.6f} +/- {np.mean(stds_dilation):.6f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| erosion contrast (original)       | 0.104527 | +/- 0.033307  |\n",
    "| dilation contrast (original)        | 0.044751  | +/- 0.019040 |\n",
    "||\n",
    "| erosion contrast (histogram adaptation) | 0.891953 | +/- 0.072304 |\n",
    "| dilation contrast (histogram adaptation)  | 0.705133 | +/- 0.171274 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14334111"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(means_dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3623020534341617"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.891953 / 0.1077034 - 0.705133 / 0.14334111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.891953 - 0.705133 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1077034"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(means_erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.104527 / 0.052519985 - 0.044751 / 0.18681999999999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a definir una función como la anterior, pero cambiando el criterio de selección de clusters. Este método de parada según la diferencia de los contrastes de los clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cluster(image, threshold=0.90, morphology_percentage_alpha = 0.025, mask_probs = None, mode = \"star_background\", channel_index = 0, metric_fnc = lambda x_mean, x_std, y_mean, y_std: (x_mean / x_std) - (y_mean / y_std)) :\n",
    "    \"\"\"\n",
    "    Filtra los clusters de una imagen binarizada para obtener el fondo.\n",
    "    \n",
    "    Parámetros:\n",
    "    image (torch.Tensor): Imagen binarizada.\n",
    "    min_background_percentage (float, opcional): Porcentaje mínimo de píxeles de fondo. Por defecto es 0.90.\n",
    "    \n",
    "    Retorna:\n",
    "    torch.Tensor: Imagen binarizada con el fondo.\n",
    "    \n",
    "    \"\"\"\n",
    "    image_knn = image[-1]\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image_knn.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image_knn == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    old_metric = 0\n",
    "    \n",
    "    if mode == \"star_background\":\n",
    "        # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "        for cluster_value in unique_values[1:]:\n",
    "            \n",
    "            add_background = torch.where(image_knn == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "            new_background = background * add_background\n",
    "            \n",
    "            if (1 - new_background.sum() / new_background.numel()) > threshold:\n",
    "                break\n",
    "            \n",
    "            background = new_background\n",
    "        \n",
    "        if mask_probs is not None:\n",
    "            background = background * mask_probs\n",
    "    \n",
    "    elif mode == \"contrast_difference\":\n",
    "        final_background = background.clone()\n",
    "        for cluster_value in unique_values[1:]:\n",
    "            bg_wo_holes = binary_closing(background, footprint=disk(image.shape[1]*morphology_percentage_alpha))\n",
    "            bg_erosion = binary_erosion(bg_wo_holes, footprint=disk(image.shape[1]*morphology_percentage_alpha))\n",
    "\n",
    "            bg_dilation = binary_dilation(background, disk(image.shape[1]*morphology_percentage_alpha*2))\n",
    "\n",
    "            if sum(bg_erosion.flatten()) >= len(bg_erosion.flatten()) * 0.99 or sum(bg_dilation.flatten()) >= len(bg_dilation.flatten())*0.99:\n",
    "                add_background = torch.where(image_knn == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "                background *= add_background\n",
    "                continue\n",
    "            \n",
    "            elif sum(bg_erosion.flatten()) == 0 or sum(bg_dilation.flatten()) == 0:\n",
    "                break\n",
    "            \n",
    "            contour_bg_erosion = measure.find_contours(bg_erosion)\n",
    "            contour_bg_dilation = measure.find_contours(bg_dilation)\n",
    "\n",
    "            # Repetir el proceso para la máscara erosionada\n",
    "            blank_image_erosion = np.zeros_like(bg_erosion, dtype=np.uint8)\n",
    "\n",
    "            contour_max_length = max(contour_bg_erosion, key=len)\n",
    "            for point in contour_max_length:\n",
    "                blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "            # Repetir el proceso para la máscara dilatada\n",
    "            blank_image_dilation = np.zeros_like(bg_dilation, dtype=np.uint8)\n",
    "\n",
    "            contour_max_length = max(contour_bg_dilation, key=len)\n",
    "            for point in contour_max_length:\n",
    "                blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "                    \n",
    "            # Calcular la diferencia entre los contornos erosionados y dilatados\n",
    "            contour_values_dilation = image.permute(1,2,0).numpy()[:,:,channel_index] * blank_image_dilation\n",
    "            contour_values_erosion = image.permute(1,2,0).numpy()[:,:,channel_index] * blank_image_erosion\n",
    "\n",
    "            bp_erosion = contour_values_erosion.flatten()[contour_values_erosion.flatten()!=0]\n",
    "            bp_dilation = contour_values_dilation.flatten()[contour_values_dilation.flatten()!=0]\n",
    "\n",
    "            # Calcular la media y la desviación típica de los valores de contraste\n",
    "            mean_erosion = np.mean(bp_erosion)\n",
    "            std_erosion = np.std(bp_erosion)\n",
    "            mean_dilation = np.mean(bp_dilation)\n",
    "            std_dilation = np.std(bp_dilation)\n",
    "\n",
    "            metric = metric_fnc(mean_erosion, std_erosion, mean_dilation, std_dilation)\n",
    "            add_background = torch.where(image_knn == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "            new_background = background * add_background\n",
    "            \n",
    "            if  metric >= threshold:\n",
    "                final_background = background.clone()\n",
    "                break\n",
    "            \n",
    "            elif metric > old_metric:\n",
    "                old_metric = metric\n",
    "                final_background = background.clone()\n",
    "            \n",
    "            background = new_background\n",
    "        background = final_background\n",
    "    elif mode == \"mixed\":\n",
    "        background_percentage = threshold[0]\n",
    "        threshold = threshold[1]\n",
    "        \n",
    "        cnt = 1\n",
    "        \n",
    "        # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "        for cluster_value in unique_values[1:]:\n",
    "            cnt += 1\n",
    "            add_background = torch.where(image_knn == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "            new_background = background * add_background\n",
    "            \n",
    "            background = new_background\n",
    "            \n",
    "            if (1 - new_background.sum() / new_background.numel()) > background_percentage:\n",
    "                break\n",
    "        \n",
    "        if mask_probs is not None:\n",
    "            background = background * mask_probs\n",
    "        \n",
    "        final_background = background.clone()\n",
    "        \n",
    "        for cluster_value in unique_values[cnt:]:\n",
    "            bg_wo_holes = binary_closing(background, footprint=disk(image.shape[1]*morphology_percentage_alpha))\n",
    "            bg_erosion = binary_erosion(bg_wo_holes, footprint=disk(image.shape[1]*morphology_percentage_alpha))\n",
    "\n",
    "            bg_dilation = binary_dilation(background, disk(image.shape[1]*morphology_percentage_alpha))\n",
    "            \n",
    "            if sum(bg_erosion.flatten()) == 0 or sum(bg_dilation.flatten()) == 0:\n",
    "                break\n",
    "            \n",
    "            contour_bg_erosion = measure.find_contours(bg_erosion)\n",
    "            contour_bg_dilation = measure.find_contours(bg_dilation)\n",
    "\n",
    "            # Repetir el proceso para la máscara erosionada\n",
    "            blank_image_erosion = np.zeros_like(bg_erosion, dtype=np.uint8)\n",
    "\n",
    "            contour_max_length = max(contour_bg_erosion, key=len)\n",
    "            for point in contour_max_length:\n",
    "                blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "            # Repetir el proceso para la máscara dilatada\n",
    "            blank_image_dilation = np.zeros_like(bg_dilation, dtype=np.uint8)\n",
    "\n",
    "            contour_max_length = max(contour_bg_dilation, key=len)\n",
    "            for point in contour_max_length:\n",
    "                blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "                    \n",
    "            # Calcular la diferencia entre los contornos erosionados y dilatados\n",
    "            contour_values_dilation = image.permute(1,2,0).numpy()[:,:,channel_index] * blank_image_dilation\n",
    "            contour_values_erosion = image.permute(1,2,0).numpy()[:,:,channel_index] * blank_image_erosion\n",
    "\n",
    "            bp_erosion = contour_values_erosion.flatten()[contour_values_erosion.flatten()!=0]\n",
    "            bp_dilation = contour_values_dilation.flatten()[contour_values_dilation.flatten()!=0]\n",
    "\n",
    "            # Calcular la media y la desviación típica de los valores de contraste\n",
    "            mean_erosion = np.mean(bp_erosion)\n",
    "            std_erosion = np.std(bp_erosion)\n",
    "            mean_dilation = np.mean(bp_dilation)\n",
    "            std_dilation = np.std(bp_dilation)\n",
    "\n",
    "            metric = metric_fnc(mean_erosion, std_erosion, mean_dilation, std_dilation)\n",
    "            \n",
    "            add_background = torch.where(image_knn == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "            new_background = background * add_background\n",
    "            \n",
    "            if  metric >= threshold:\n",
    "                final_background = background.clone()\n",
    "                break\n",
    "            \n",
    "            elif metric > old_metric:\n",
    "                old_metric = metric\n",
    "                final_background = background.clone()\n",
    "                \n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda de código donde se realizan algunas pruebas para comprobar los resultados de la segmentación\n",
    "# Más adelante se implementa este código en una función que se puede llamar desde el script principal\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 2048),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=11, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,4):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    morphology_percentage_alpha = 0.025\n",
    "    \n",
    "    # Si se utiliza la imagen original\n",
    "    # threshold = 1.75\n",
    "    \n",
    "    # Si se utiliza la imagen adaptada\n",
    "    threshold = 3.5\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "    final_background = background.clone()\n",
    "    \n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    old_metric = 0\n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        bg_wo_holes = binary_closing(background, footprint=disk(image_original.shape[1]*morphology_percentage_alpha))\n",
    "        bg_erosion = binary_erosion(bg_wo_holes, footprint=disk(image_original.shape[1]*morphology_percentage_alpha))\n",
    "\n",
    "        bg_dilation = binary_dilation(background, disk(image_original.shape[1]*morphology_percentage_alpha*2))\n",
    "\n",
    "        if sum(bg_erosion.flatten()) == len(bg_erosion.flatten()) or sum(bg_dilation.flatten()) == len(bg_dilation.flatten()):\n",
    "            add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "            background *= add_background\n",
    "            continue\n",
    "        elif sum(bg_erosion.flatten()) == 0 or sum(bg_dilation.flatten()) == 0:\n",
    "            break\n",
    "        \n",
    "        contour_bg_erosion = measure.find_contours(bg_erosion)\n",
    "        contour_bg_dilation = measure.find_contours(bg_dilation)\n",
    "\n",
    "        # Repetir el proceso para la máscara erosionada\n",
    "        blank_image_erosion = np.zeros_like(bg_erosion, dtype=np.uint8)\n",
    "\n",
    "        contour_max_length = max(contour_bg_erosion, key=len)\n",
    "        for point in contour_max_length:\n",
    "            blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "        # Repetir el proceso para la máscara dilatada\n",
    "        blank_image_dilation = np.zeros_like(bg_dilation, dtype=np.uint8)\n",
    "\n",
    "        contour_max_length = max(contour_bg_dilation, key=len)\n",
    "        for point in contour_max_length:\n",
    "            blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "                \n",
    "        # Calcular la diferencia entre los contornos erosionados y dilatados\n",
    "        \n",
    "        # ## Valores de KMeans\n",
    "        # contour_values_dilation = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_dilation\n",
    "        # contour_values_erosion = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_erosion\n",
    "        \n",
    "        ## Valores de Original\n",
    "        # contour_values_dilation = image_original.permute(1,2,0).numpy()[:,:,0] * blank_image_dilation\n",
    "        # contour_values_erosion = image_original.permute(1,2,0).numpy()[:,:,0] * blank_image_erosion\n",
    "        \n",
    "        # ## Valores de Adaptive Equalization\n",
    "        contour_values_dilation = image_original.permute(1,2,0).numpy()[:,:,0] * blank_image_dilation\n",
    "        contour_values_erosion = image_original.permute(1,2,0).numpy()[:,:,0] * blank_image_erosion\n",
    "\n",
    "        bp_erosion = contour_values_erosion.flatten()[contour_values_erosion.flatten()!=0]\n",
    "        bp_dilation = contour_values_dilation.flatten()[contour_values_dilation.flatten()!=0]\n",
    "\n",
    "        # Calcular la media y la desviación típica de los valores de contraste\n",
    "        mean_erosion = np.mean(bp_erosion)\n",
    "        std_erosion = np.std(bp_erosion)\n",
    "        mean_dilation = np.mean(bp_dilation)\n",
    "        std_dilation = np.std(bp_dilation)\n",
    "    \n",
    "        j, i = divmod(cnt, 2)\n",
    "        \n",
    "        # metric = (mean_erosion - std_erosion) - (mean_dilation - std_dilation)\n",
    "        metric = mean_erosion / std_erosion - mean_dilation / std_dilation\n",
    "        # metric = mean_erosion - mean_dilation\n",
    "        # metric = mean_erosion*std_erosion - mean_dilation*std_dilation\n",
    "\n",
    "        ax[i, j].set_title(f\"Contrast difference: {metric}\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if  metric >= threshold and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "        \n",
    "        elif not solution and metric > old_metric:\n",
    "            old_metric = metric\n",
    "            final_background = background.clone()\n",
    "            \n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda de código donde se realizan algunas pruebas para comprobar los resultados de la segmentación\n",
    "# Más adelante se implementa este código en una función que se puede llamar desde el script principal\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 2048),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(5,15):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    morphology_percentage_alpha = 0.025\n",
    "    \n",
    "    min_background_percentage = 0.5\n",
    "    \n",
    "    # Si se utiliza la imagen original\n",
    "    # threshold = 1.5\n",
    "    \n",
    "    # Si se utiliza la imagen adaptada\n",
    "    threshold = 0.19\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "    final_background = background.clone()\n",
    "    \n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    control = 1\n",
    "    solution = False\n",
    "    \n",
    "    old_metric = 0\n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        control += 1\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            break\n",
    "        \n",
    "        cnt += 1\n",
    "    for cluster_value in unique_values[control:]:\n",
    "        bg_wo_holes = binary_closing(background, footprint=disk(image_original.shape[1]*morphology_percentage_alpha))\n",
    "        bg_erosion = binary_erosion(bg_wo_holes, footprint=disk(image_original.shape[1]*morphology_percentage_alpha))\n",
    "\n",
    "        bg_dilation = binary_dilation(background, disk(image_original.shape[1]*morphology_percentage_alpha*2))\n",
    "\n",
    "        if sum(bg_erosion.flatten()) == len(bg_erosion.flatten()) or sum(bg_dilation.flatten()) == len(bg_dilation.flatten()) or sum(bg_erosion.flatten()) == 0 or sum(bg_dilation.flatten()) == 0:\n",
    "            print(f\"Cluster {cluster_value} has been added to the background\")\n",
    "            break\n",
    "        \n",
    "        contour_bg_erosion = measure.find_contours(bg_erosion)\n",
    "        contour_bg_dilation = measure.find_contours(bg_dilation)\n",
    "\n",
    "        # Repetir el proceso para la máscara erosionada\n",
    "        blank_image_erosion = np.zeros_like(bg_erosion, dtype=np.uint8)\n",
    "\n",
    "        contour_max_length = max(contour_bg_erosion, key=len)\n",
    "        for point in contour_max_length:\n",
    "            blank_image_erosion[int(point[0]), int(point[1])] = 1\n",
    "\n",
    "        # Repetir el proceso para la máscara dilatada\n",
    "        blank_image_dilation = np.zeros_like(bg_dilation, dtype=np.uint8)\n",
    "\n",
    "        contour_max_length = max(contour_bg_dilation, key=len)\n",
    "        for point in contour_max_length:\n",
    "            blank_image_dilation[int(point[0]), int(point[1])] = 1\n",
    "                \n",
    "        # Calcular la diferencia entre los contornos erosionados y dilatados\n",
    "        \n",
    "        # ## Valores de KMeans\n",
    "        # contour_values_dilation = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_dilation\n",
    "        # contour_values_erosion = image.permute(1,2,0).numpy()[:,:,-1] * blank_image_erosion\n",
    "        \n",
    "        ## Valores de Original\n",
    "        # contour_values_dilation = image_original.permute(1,2,0).numpy()[:,:,0] * blank_image_dilation\n",
    "        # contour_values_erosion = image_original.permute(1,2,0).numpy()[:,:,0] * blank_image_erosion\n",
    "        \n",
    "        # ## Valores de Adaptive Equalization\n",
    "        contour_values_dilation = image_original.permute(1,2,0).numpy()[:,:,2] * blank_image_dilation\n",
    "        contour_values_erosion = image_original.permute(1,2,0).numpy()[:,:,2] * blank_image_erosion\n",
    "\n",
    "        bp_erosion = contour_values_erosion.flatten()[contour_values_erosion.flatten()!=0]\n",
    "        bp_dilation = contour_values_dilation.flatten()[contour_values_dilation.flatten()!=0]\n",
    "\n",
    "        # Calcular la media y la desviación típica de los valores de contraste\n",
    "        mean_erosion = np.mean(bp_erosion)\n",
    "        std_erosion = np.std(bp_erosion)\n",
    "        mean_dilation = np.mean(bp_dilation)\n",
    "        std_dilation = np.std(bp_dilation)\n",
    "    \n",
    "        j, i = divmod(cnt, 2)\n",
    "        \n",
    "        # metric = (mean_erosion - std_erosion) - (mean_dilation - std_dilation)\n",
    "        # metric = mean_erosion / std_erosion - mean_dilation / std_dilation\n",
    "        metric = mean_erosion - mean_dilation\n",
    "        # metric = mean_erosion*std_erosion - mean_dilation*std_dilation\n",
    "        \n",
    "        ax[i, j].set_title(f\"Contrast difference: {metric}\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if  metric >= threshold and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "        \n",
    "        elif not solution and metric > old_metric:\n",
    "            old_metric = metric\n",
    "            final_background = background.clone()\n",
    "            \n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos una función definida que nos selecciona los primeros clusters convenientes como fondo, vamos a definir una metodología de evaluación y vamos a comprobar que tal funciona nuestra primera aproximación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://10.120.206.1:8891/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "from skimage import morphology, exposure\n",
    "from skimage.morphology import disk, binary_closing, binary_erosion, binary_dilation\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 2048),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=5, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    # output = filter_cluster(image, threshold = 0.93).expand_as(mask)\n",
    "    output = filter_cluster(image, threshold = 3, morphology_percentage_alpha = 0.025, mode = \"contrast_difference\", channel_index = 2).expand_as(mask)\n",
    "    # output = filter_cluster(image, threshold = (0.60, 3), morphology_percentage_alpha = 0.025, mode = \"mixed\", channel_index = 2).expand_as(mask)\n",
    "    \n",
    "    output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    output = morphology.remove_small_objects(output, min_size=500)\n",
    "    output = torch.tensor(output).unsqueeze(0)\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    # Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 3:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de K-Means***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.301938 | 0.21419  |\n",
    "| f1        | 0.42291  | 0.256297 |\n",
    "| precision | 0.505177 | 0.333949 |\n",
    "| accuracy  | 0.844327 | 0.128148 |\n",
    "| recall    | 0.587245 | 0.329879 |\n",
    "\n",
    "(NOTA: A medida que aumento el número de clusters, a 9, 11, 13 y 15, obtengo mejores resultados, puede tener algún inconveniente?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar ciertas mejoras como por ejemplo, aplicar operadores morfológicos para tratar de eliminar las estrellas que acaparan demasiada atención de la técnica de agrupamiento de datos, aplicar algún filtro sencillo con el que consigamos una mejor diferenciación entre los clústeres e intentar aplicar alguna técnica de umbralización con la que se escoja de mejor manera el mejor conjunto de clusters para segmentar la nebulosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AREA OPENING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "imagen = dataset[40][0]\n",
    "plt.imshow(imagen.permute(1,2,0).numpy(), cmap='gray')\n",
    "\n",
    "imagen_opening = morphology.area_opening(imagen.permute(1,2,0)[:,:,0].numpy(), area_threshold=500)\n",
    "# imagen_opening = morphology.remove_small_objects(imagen.permute(1,2,0)[:,:,0].numpy(), min_size=500)\n",
    "plt.imshow(imagen_opening, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.93).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfológicos (opening en área)***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.474498 | 0.251984 |\n",
    "| f1        | 0.600424 | 0.260653 |\n",
    "| precision | 0.661401 | 0.323928 |\n",
    "| accuracy  | 0.865881 | 0.162479 |\n",
    "| recall    | 0.758522 | 0.246124 |\n",
    "\n",
    "Como se puede observar, se consiguen mejores resultados aplicando operadores morfológicos que sin ellos.\n",
    "Parece ser que visualmente al procesar la imagen de la última manera que hemos hecho se concentran los valores de los píxeles en ciertos valores, por lo que vamos a imprimir el histograma de algunas imágenes para ver si esto es cierto y vamos a comprobar que no influya demasiado a la hora de realizar el KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA EJECUTAR ESTA CELDA CORRECTAMENTE HACE FALTA HABER EJECUTADO EL EXPERIMENTO ANTERIOR\n",
    "for i in range(0, 5):\n",
    "    im_op_morf = dataset[i][0].permute(1,2,0).numpy()[:,:,1]\n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(im_op_morf, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(im_op_morf)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "for i in range(0, 5):\n",
    "    im_op_morf = dataset[i][0].permute(1,2,0).numpy()[:,:,1]\n",
    "    # Se podría hacer un reescalado de la intensidad de las imagenes del mínimo al máximo (lineal, simplemente mover el histograma)\n",
    "    # pero haciendo de esta forma conseguimos resaltar las partes de nebulosa respecto de las de fondo\n",
    "    image_reescaled = exposure.rescale_intensity(im_op_morf, in_range = (im_op_morf.max()/5, im_op_morf.max()), out_range = (0, 1))\n",
    "    \n",
    "    # Probamos con un ajuste logarítmico de la intensidad\n",
    "    # image_reescaled = exposure.adjust_log(im_op_morf, gain=1.2, inv=True)\n",
    "    \n",
    "    # También probamos con una ecualización del histograma para que las intensidades estén más repartidas\n",
    "    # image_reescaled = exposure.equalize_hist(im_op_morf)\n",
    "    \n",
    "    # Y por último, probamos con una ecualización adaptativa del histograma\n",
    "    # image_reescaled = exposure.equalize_adapthist(im_op_morf, kernel_size = im_op_morf.shape[0]//10)\n",
    "    \n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(image_reescaled, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(image_reescaled)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.rescale_intensity, concat = True, in_range = (1/5, 1), out_range = (0, 1)),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, kernel_size = 5),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.adjust_log, concat = True, gain = 1.5, inv = True),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.rescale_intensity, concat = True, in_range = (1/5, 1), out_range = (0, 1)),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, kernel_size = 5),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.adjust_log, concat = True, gain = 1.5, inv = True),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.93).expand_as(mask)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfológicos (opening en área) y adaptación del histograma***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.462187 | 0.251906 |\n",
    "| f1        | 0.588433 | 0.261978 |\n",
    "| precision | 0.653917 | 0.331209 |\n",
    "| accuracy  | 0.85844  | 0.166378 |\n",
    "| recall    | 0.753286 | 0.24564  |\n",
    "\n",
    "Como se puede observar, los mejores resultados obtenidos son muy similares (iguales si se hace una adaptación del histograma lineal) a los resultados obtenidos sin la adaptación del histograma (después de hacer el operador morfológico), vamos a probar a continuación a hacer una adaptación del histograma a la imagen original y después hacer los operadores morfológicos y el KMeans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.93).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con adaptación del histograma y operadores morfológicos (opening en área)***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.482382 | 0.243033  |\n",
    "| f1        | 0.610257 | 0.255888  |\n",
    "| precision | 0.646103 | 0.303263  |\n",
    "| accuracy  | 0.911641 | 0.0766837 |\n",
    "| recall    | 0.747889 | 0.289217  |\n",
    "\n",
    "Como podemos observar, los resultados practicamente iguales que los anteriores aunque, al ver las imágenes me hace sospechar que un filtro como por ejemplo Gaussiano después de la adaptación del histograma podría hacer mejorar los resultados considerablemente. Otra mejora que veo posible es la de incluir el operador morfológico de closing en el resultado final como postprocesado, aunque de este apartado podemos hablar más adelante (dejamos los resultados en la siguiente tabla haciendo una pequeña prueba con esta mejora)\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.514091 | 0.257969 |\n",
    "| f1        | 0.635843 | 0.262296 |\n",
    "| precision | 0.654544 | 0.309503 |\n",
    "| accuracy  | 0.903982 | 0.104944 |\n",
    "| recall    | 0.814793 | 0.249345 |\n",
    "\n",
    "Como última prueba de este apartado vamos a probar a eliminar por completo gracias a los operadores morfológicos el fondo de estrellas de las imágenes, en vez de intentar reducir su visibilidad como estabamos haciendo hasta ahora (gracias a la función area_opening). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BINARY OPENING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.morphology as morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (8,8))\n",
    "imagen = dataset[1][0].permute(1,2,0).numpy()[:,:,0]\n",
    "imagen_preproc = np.copy(imagen)\n",
    "\n",
    "ax[0].imshow(imagen, cmap='gray')\n",
    "\n",
    "imagen_filt = ndimage.gaussian_filter(imagen, sigma=3)\n",
    "imagen_filt[imagen == 0] = 0\n",
    "\n",
    "imagen_zonas_claras_peq = imagen > (imagen_filt + np.std(imagen))\n",
    "\n",
    "imagen_zonas_claras_peq = morphology.binary_opening(imagen_zonas_claras_peq, morphology.disk(2))\n",
    "    \n",
    "imagen_preproc = (imagen_preproc - np.min(imagen_preproc))\n",
    "imagen_preproc[imagen_zonas_claras_peq] = 0\n",
    "\n",
    "# imagen_opening = morphology.remove_small_objects(imagen.permute(1,2,0)[:,:,0].numpy(), min_size=500)\n",
    "ax[1].imshow(imagen_preproc, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.93).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfólogicos para eliminar el fondo de estrellas (opening binario)***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.340304 | 0.202407 |\n",
    "| f1        | 0.474101 | 0.230723 |\n",
    "| precision | 0.548508 | 0.328343 |\n",
    "| accuracy  | 0.860052 | 0.112781 |\n",
    "| recall    | 0.629009 | 0.295397 |\n",
    "\n",
    "Como podemos comprobar, funciona algo mejor que solo utilizar KMeans aunque bastante parecido, como se puede observar en las imágenes observadas. Vamos a probar a unificar las dos técnicas de operadores morfológicos que hemos aplicado, primero eliminamos el fondo de estrellas y después intentamos visualizar lo menos posible los restos que queden de el (primero binary_opening y después area_opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.94).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfológicos (ambas técnicas)***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.472936 | 0.234044 |\n",
    "| f1        | 0.605284 | 0.24067  |\n",
    "| precision | 0.67945  | 0.311074 |\n",
    "| accuracy  | 0.878765 | 0.142001 |\n",
    "| recall    | 0.726142 | 0.241789 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver los resultados son muy parecidos a solo realizar la técnica de operadores morfológicos que NO elimina el fondo de estrellas por completo, aunque hemos tenido que subir un poco el umbral manual (porcentaje de píxeles de fondo) para obtener ese resultado, por lo que vamos a comprobar los resultados que da con una adaptación del histograma entre ambas técnicas de operadores morfológicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.94).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con Opening binario, adaptación del histograma y opening en área***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.496861 | 0.230796  |\n",
    "| f1        | 0.62982  | 0.227609  |\n",
    "| precision | 0.661146 | 0.282945  |\n",
    "| accuracy  | 0.916543 | 0.0739382 |\n",
    "| recall    | 0.769579 | 0.246387  |\n",
    "\n",
    "Vamos a comprobar finalmente que tal funcionaría con el postprocesado sencillo que probamos anteriormente\n",
    "\n",
    "***Resultados de KMeans con Opening binario, adaptación del histograma y opening en área + postprocesado***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.534588 | 0.250919  |\n",
    "| f1        | 0.658135 | 0.243586  |\n",
    "| precision | 0.656112 | 0.29426   |\n",
    "| accuracy  | 0.917111 | 0.0781187 |\n",
    "| recall    | 0.841828 | 0.223383  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTRO GAUSSIANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    image = dataset[i][0].permute(1,2,0).numpy()[:,:,0]\n",
    "    \n",
    "    # image_reescaled = exposure.equalize_hist(image, nbins = 640)\n",
    "    \n",
    "    # im_op_morf = morphology.area_opening(image_reescaled, area_threshold=200)\n",
    "    \n",
    "    im_op_morf = morphology.area_opening(image, area_threshold=200)\n",
    "    \n",
    "    imagen_filter = ndimage.gaussian_filter(im_op_morf, sigma = 4)\n",
    "    \n",
    "    \n",
    "    # Se podría hacer un reescalado de la intensidad de las imagenes del mínimo al máximo (lineal, simplemente mover el histograma)\n",
    "    # pero haciendo de esta forma conseguimos resaltar las partes de nebulosa respecto de las de fondo\n",
    "    # image_reescaled = exposure.rescale_intensity(im_op_morf, in_range = (im_op_morf.max()/5, im_op_morf.max()), out_range = (0, 1))\n",
    "    \n",
    "    # Probamos con un ajuste logarítmico de la intensidad\n",
    "    # image_reescaled = exposure.adjust_log(im_op_morf, gain=1.2, inv=True)\n",
    "    \n",
    "    # También probamos con una ecualización del histograma para que las intensidades estén más repartidas\n",
    "    # image_reescaled = exposure.equalize_hist(im_op_morf, nbins = 640)\n",
    "    \n",
    "    # Y por último, probamos con una ecualización adaptativa del histograma\n",
    "    # image_reescaled = exposure.equalize_adapthist(im_op_morf, kernel_size = im_op_morf.shape[0]//10)\n",
    "    \n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(imagen_filter, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(imagen_filter)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(40,50):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.89\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 2048),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 100, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 7),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, threshold = 0.93).expand_as(mask)\n",
    "    # output = filter_cluster(image, threshold=0.15, morphology_percentage_alpha = 0.025, mode = \"contrast_difference\", channel_index = -2).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = output.permute(1,2,0).numpy()[:,:,0]\n",
    "    # output = morphology.binary_closing(output, footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con opening en área y Filtro Gaussiano (sigma 5)***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.533148 | 0.247184 |\n",
    "| f1        | 0.65724  | 0.245682 |\n",
    "| precision | 0.732878 | 0.29252  |\n",
    "| accuracy  | 0.901664 | 0.115164 |\n",
    "| recall    | 0.758274 | 0.244278 |\n",
    "\n",
    "***Resultados de KMeans con adaptación del histograma, opening en área y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.51504  | 0.252026  |\n",
    "| f1        | 0.638368 | 0.258574  |\n",
    "| precision | 0.694062 | 0.30799   |\n",
    "| accuracy  | 0.918851 | 0.0819133 |\n",
    "| recall    | 0.751193 | 0.286227  |\n",
    "\n",
    "***Resultados de KMeans con opening binario, opening en área y Filtro Gaussiano (sigma 5)***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.50307  | 0.227348 |\n",
    "| f1        | 0.636952 | 0.22226  |\n",
    "| precision | 0.701959 | 0.301808 |\n",
    "| accuracy  | 0.903936 | 0.106539 |\n",
    "| recall    | 0.763739 | 0.249194 |\n",
    "\n",
    "***Resultados de KMeans con opening binario, adaptación del histograma, opening en área y Filtro Gaussiano (sigma 5)***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.537252 | 0.246508 |\n",
    "| f1        | 0.663492 | 0.228315 |\n",
    "| precision | 0.719191 | 0.298549 |\n",
    "| accuracy  | 0.925891 | 0.073396 |\n",
    "| recall    | 0.776446 | 0.243754 |\n",
    "\n",
    "***Resultados de KMeans con opening binario, adaptación del histograma, opening en área y Filtro Gaussiano (sigma 5) + postprocesado***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.544275 | 0.244476  |\n",
    "| f1        | 0.670401 | 0.224853  |\n",
    "| precision | 0.728293 | 0.294329  |\n",
    "| accuracy  | 0.927701 | 0.0734514 |\n",
    "| recall    | 0.777289 | 0.24409   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMBRALIZACIÓN (para evitar tener que elegir un umbral en el porcentaje de píxeles de fondo)\n",
    "(IGNORAR DE MOMENTO, NECESITA REFLEXIÓN Y DESARROLLO - 14/06/24)\n",
    "\n",
    "Necesitamos algún método, como por ejemplo un test estadístico, que nos ayude a que la división de clusters en fondo y nebulosa sea más personalizada para cada imagen de lo que es un umbral de porcentaje de píxeles de fondo.\n",
    "\n",
    "Algunas ideas que se me han ocurrido han sido:\n",
    "- Aplicar algún método, como Otsu, donde se considera cada cluster como una clase y se busca la división de los datos (a través de un umbral) que minimize la varianza intra-clase.\n",
    "\n",
    "- Intentar modelar los clúster como una Mixtura de Gaussianas (GMM, por sus siglas en inglés Gaussian Mixture Model) de dos Gaussianas (o más, pero por simplicidad y para empezar solo con 2)\n",
    "\n",
    "(NOTA: Aunque utilicemos otros métodos para separar los clústers en fondo y nebulosa, podemos seguir utilizando el umbral del porcentaje manual para descartar los primeros clústeres que van a ser la mayoría de veces solo fondo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    imagen = dataset[i][0].permute(1,2,0).numpy()[:,:,0]\n",
    "    imagen = exposure.equalize_hist(imagen, nbins = 1024)\n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(imagen, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(imagen)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Método de Otsu (simple)\n",
    "Vamos a comenzar aplicando al KMeans una umbralización de Otsu, tanto de manera general como local, para comprobar si consigue separar los clusters del KMeans en fondo y nebulosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    # ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "rd.seed(42)\n",
    "random_indexs = rd.sample(range(len(dataset)), 3)\n",
    "for index in random_indexs:\n",
    "    plot_all(*dataset[index], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image_knn = image_original[-1]\n",
    "    \n",
    "    image = filter_cluster(image_knn, min_background_percentage = 0.8).expand_as(mask).permute(1,2,0).numpy()[:,:,0]\n",
    "    \n",
    "    image = image * image_knn.numpy()\n",
    "    # Calculamos el histograma de image y lo recortamos desde el minimo distinto de 0 al maximo\n",
    "    image_thr = image[image != 0]\n",
    "    # image_thr = threshold_local(image_thr)[0]\n",
    "    \n",
    "    image_thr = threshold_otsu(image_thr)\n",
    "    \n",
    "    fig, axis = plt.subplots(1,2, figsize = (12,8))\n",
    "    \n",
    "    axis[0].imshow(image, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen en escala de grises\")\n",
    "    axis[1].hist(image)\n",
    "    axis[1].set_title(\"Histograma de la imagen\")\n",
    "    \n",
    "    axis[1].axvline(image_thr, color='r')\n",
    "    \n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(image > image_thr, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "    # min_add_background_percentage = 0.2\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "        #     if add_background.sum() / add_background.numel() > min_add_background_percentage:\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         continue\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.94).expand_as(mask)\n",
    "    # output = output.permute(1,2,0).numpy()[:,:,0]\n",
    "    # output = morphology.binary_closing(output, footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy C-Means (FCM)\n",
    "Vamos a continuar probando una de las variantes del algoritmo de KMeans. Este algoritmo se diferencia del anterior en que, en vez de aportar un cluster al que pertenece cada cluster, aporta un nivel de pertenencia entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "threshold = None\n",
    "threshold = 0.25\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 100, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 4),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyFCM(concat=True, c=7, m=2, error = 0.005, maxiter=15, seed=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(70,85):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    if threshold is not None:\n",
    "        maxs = image_original[-2]\n",
    "        probs_mask = maxs > threshold\n",
    "        final_background = final_background * probs_mask\n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(2))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "threshold = None\n",
    "threshold = 0.25\n",
    "\n",
    "mask_probs = None\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 100, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 4),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyFCM(concat=True, c=7, m=2, error = 0.005, maxiter=15, seed=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c_train.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_clusters = image[-1]\n",
    "    \n",
    "    if threshold is not None:\n",
    "        mask_probs = image[-2]\n",
    "        mask_probs = mask_probs > threshold\n",
    "    \n",
    "    output = filter_cluster(image_clusters, min_background_percentage = 0.93, mask_probs = mask_probs).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = output.permute(1,2,0).numpy()[:,:,0]\n",
    "    # output = morphology.binary_closing(output, footprint=morphology.disk(2))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de FCM (simple) c=7***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.375927 | 0.219531  |\n",
    "| f1        | 0.512536 | 0.2191    |\n",
    "| precision | 0.560385 | 0.282301  |\n",
    "| accuracy  | 0.883111 | 0.0877457 |\n",
    "| recall    | 0.670768 | 0.29144   |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) c=7***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.372125 | 0.226079  |\n",
    "| f1        | 0.505774 | 0.229752  |\n",
    "| precision | 0.566774 | 0.294991  |\n",
    "| accuracy  | 0.884306 | 0.0873961 |\n",
    "| recall    | 0.625326 | 0.28131   |\n",
    "\n",
    "***Resultados de FCM (simple) c=9***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.352356 | 0.213078 |\n",
    "| f1        | 0.487316 | 0.22107  |\n",
    "| precision | 0.530062 | 0.288398 |\n",
    "| accuracy  | 0.86052  | 0.110891 |\n",
    "| recall    | 0.68024  | 0.297449 |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) c=9***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.329139 | 0.2173   |\n",
    "| f1        | 0.458464 | 0.232549 |\n",
    "| precision | 0.530828 | 0.313011 |\n",
    "| accuracy  | 0.860277 | 0.110107 |\n",
    "| recall    | 0.5836   | 0.284304 |\n",
    "\n",
    "***Resultados de FCM (simple) c=5***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.346018 | 0.206797 |\n",
    "| f1        | 0.480247 | 0.227996 |\n",
    "| precision | 0.544016 | 0.307694 |\n",
    "| accuracy  | 0.861736 | 0.107387 |\n",
    "| recall    | 0.647818 | 0.299709 |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) c=5***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.347282 | 0.208122 |\n",
    "| f1        | 0.481238 | 0.229512 |\n",
    "| precision | 0.547664 | 0.309927 |\n",
    "| accuracy  | 0.862562 | 0.107312 |\n",
    "| recall    | 0.640019 | 0.294752 |\n",
    "\n",
    "Se puede considerar esta solución como un borrador de fondo de estrellas, ya que al aplicar un umbral de pertenencia en las imágenes siempre descarta las estrellas del fondo, vamos a comparar que tal funciona respecto nuestro borrador de fondo de estrellas con operadores morfológicos.\n",
    "\n",
    "***Resultados de FCM (simple) con operador binario***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.363835 | 0.209597  |\n",
    "| f1        | 0.500761 | 0.21994   |\n",
    "| precision | 0.534574 | 0.295538  |\n",
    "| accuracy  | 0.871749 | 0.0907226 |\n",
    "| recall    | 0.689259 | 0.262586  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con operador binario***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.351067 | 0.212059  |\n",
    "| f1        | 0.484921 | 0.228886  |\n",
    "| precision | 0.534494 | 0.308186  |\n",
    "| accuracy  | 0.871943 | 0.0904017 |\n",
    "| recall    | 0.618003 | 0.256574  |\n",
    "\n",
    "***Resultados de FCM (simple) con operador en área***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.455727 | 0.217641 |\n",
    "| f1        | 0.595032 | 0.214648 |\n",
    "| precision | 0.644525 | 0.302007 |\n",
    "| accuracy  | 0.901368 | 0.082002 |\n",
    "| recall    | 0.749689 | 0.248432 |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con operador en área***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.441428 | 0.231196  |\n",
    "| f1        | 0.575318 | 0.239802  |\n",
    "| precision | 0.638409 | 0.319608  |\n",
    "| accuracy  | 0.900503 | 0.0823982 |\n",
    "| recall    | 0.675645 | 0.272046  |\n",
    "\n",
    "***Resultados de FCM (simple) con ambos operadores morfológicos***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.434979 | 0.216478  |\n",
    "| f1        | 0.57457  | 0.216249  |\n",
    "| precision | 0.630748 | 0.315386  |\n",
    "| accuracy  | 0.899437 | 0.0741227 |\n",
    "| recall    | 0.739725 | 0.250791  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con ambos operadores morfológicos***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.416596 | 0.224087  |\n",
    "| f1        | 0.551497 | 0.239701  |\n",
    "| precision | 0.620918 | 0.331917  |\n",
    "| accuracy  | 0.898226 | 0.0734305 |\n",
    "| recall    | 0.654533 | 0.285514  |\n",
    "\n",
    "***Resultados de FCM (simple) con adaptación del histograma***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.344041 | 0.194668  |\n",
    "| f1        | 0.480948 | 0.220531  |\n",
    "| precision | 0.442844 | 0.266004  |\n",
    "| accuracy  | 0.856461 | 0.0772394 |\n",
    "| recall    | 0.762065 | 0.266871  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con adaptación del histograma***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.441428 | 0.231196  |\n",
    "| f1        | 0.575318 | 0.239802  |\n",
    "| precision | 0.638409 | 0.319608  |\n",
    "| accuracy  | 0.900503 | 0.0823982 |\n",
    "| recall    | 0.675645 | 0.272046  |\n",
    "\n",
    "***Resultados de FCM (simple) con apertura en área y adaptación del histograma***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.377132 | 0.19476   |\n",
    "| f1        | 0.518873 | 0.209905  |\n",
    "| precision | 0.473287 | 0.292068  |\n",
    "| accuracy  | 0.866084 | 0.0595233 |\n",
    "| recall    | 0.85641  | 0.204314  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.45 por que menos no habia cambio) con apertura en área y adaptación del histograma***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.366558 | 0.193885 |\n",
    "| f1        | 0.507718 | 0.208752 |\n",
    "| precision | 0.467925 | 0.292669 |\n",
    "| accuracy  | 0.864792 | 0.059048 |\n",
    "| recall    | 0.832137 | 0.214636 |\n",
    "\n",
    "***Resultados de FCM (simple) con apertura binaria, adaptación del histograma y opening en área***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.439533 | 0.198234  |\n",
    "| f1        | 0.583274 | 0.204723  |\n",
    "| precision | 0.577765 | 0.283441  |\n",
    "| accuracy  | 0.901501 | 0.0655886 |\n",
    "| recall    | 0.797216 | 0.234162  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con apertura binaria, adaptación del histograma y opening en área***\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.436168 | 0.200064 |\n",
    "| f1        | 0.579458 | 0.206447 |\n",
    "| precision | 0.575386 | 0.285284 |\n",
    "| accuracy  | 0.9012   | 0.065409 |\n",
    "| recall    | 0.789347 | 0.234885 |\n",
    "\n",
    "***Resultados de FCM (simple) con apertura binaria y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.449819 | 0.231084  |\n",
    "| f1        | 0.58527  | 0.228024  |\n",
    "| precision | 0.632938 | 0.292495  |\n",
    "| accuracy  | 0.900511 | 0.0832081 |\n",
    "| recall    | 0.737613 | 0.275606  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con apertura binaria y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.442555 | 0.235778  |\n",
    "| f1        | 0.575977 | 0.237933  |\n",
    "| precision | 0.636301 | 0.301989  |\n",
    "| accuracy  | 0.900828 | 0.0832787 |\n",
    "| recall    | 0.683621 | 0.296212  |\n",
    "\n",
    "***Resultados de FCM (simple) con apertura en área y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.492137 | 0.23423   |\n",
    "| f1        | 0.625384 | 0.225294  |\n",
    "| precision | 0.678883 | 0.302424  |\n",
    "| accuracy  | 0.909404 | 0.0813395 |\n",
    "| recall    | 0.771316 | 0.252718  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con apertura en área y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.480827 | 0.24135   |\n",
    "| f1        | 0.611565 | 0.240507  |\n",
    "| precision | 0.674853 | 0.313602  |\n",
    "| accuracy  | 0.908992 | 0.0808518 |\n",
    "| recall    | 0.713841 | 0.280797  |\n",
    "\n",
    "***Resultados de FCM (simple) con apertura binaria, apertura en área y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.486966 | 0.242643  |\n",
    "| f1        | 0.618106 | 0.233243  |\n",
    "| precision | 0.675286 | 0.317727  |\n",
    "| accuracy  | 0.909146 | 0.0742083 |\n",
    "| recall    | 0.774254 | 0.252611  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con apertura binaria, apertura en área y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.477186 | 0.250463  |\n",
    "| f1        | 0.605349 | 0.248521  |\n",
    "| precision | 0.670173 | 0.327936  |\n",
    "| accuracy  | 0.908301 | 0.0745995 |\n",
    "| recall    | 0.707859 | 0.279038  |\n",
    "\n",
    "***Resultados de FCM (simple) con apertura binaria, adaptación del histograma y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.504703 | 0.21734   |\n",
    "| f1        | 0.640941 | 0.213398  |\n",
    "| precision | 0.648524 | 0.292695  |\n",
    "| accuracy  | 0.918512 | 0.0639917 |\n",
    "| recall    | 0.804142 | 0.225611  |\n",
    "\n",
    "***Resultados de FCM (threshold = 0.25) con apertura binaria, adaptación del histograma y filtro gaussiano***\n",
    "\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.495991 | 0.226867  |\n",
    "| f1        | 0.62954  | 0.228345  |\n",
    "| precision | 0.641458 | 0.302026  |\n",
    "| accuracy  | 0.91726  | 0.0646175 |\n",
    "| recall    | 0.773269 | 0.242168  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COSAS PARA HACER:\n",
    "- Early Stop porcentaje de pixeles de fondo haciendo una comparación del contraste de los cluster\n",
    "- Mirar mixtura de Gaussianas\n",
    "- Clasificación supervisada por ventada (problema binario - si hay nebulosa en la ventana o no)\n",
    "- Segmentación supervisada - lanzar pruebas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
