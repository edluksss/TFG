{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de segmentación con el Catálogo Morfológico de Nebulosas Planetarias del IAC (SUPERVISADO)\n",
    "En este documento vamos a probar las técnicas comentadas por Diego Cantorna en el documento de astrogestem (disponible en la carpeta astrosegstem de este mismo repositorio) y vamos a añadir ciertas técnicas y mejoras. Todas las técnicas testeadas en este Jupyter Notebook son de aprendizaje no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga del Dataset\n",
    "Vamos a definir una clase, que tome como base la clase Dataset de Pytorch, para poder cargar todo nuestro conjunto de imágenes de uno o varios canales con su máscara correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Vamos a cambiar el directorio de trabajo\")\n",
    "\n",
    "# Indicamos la ruta del directorio de trabajo\n",
    "route = os.getcwd()+ \"/TFG/test/PNe_segmentation\"\n",
    "os.chdir(route)\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\" El directorio actual es:\", current_directory)\n",
    "\n",
    "# Listamos el contenido del directorio\n",
    "files = os.listdir(current_directory)\n",
    "print(\" Contenido del directorio actual:\")\n",
    "for file in files:\n",
    "    print(\"\\t\",file)\n",
    "    \n",
    "# Listamos el contenido del directorio de las máscaras\n",
    "# masks_directory = route+\"TFG\\\\test\\\\PNe_segmentation\\\\masks\"\n",
    "# data_directory = route+\"TFG\\\\test\\\\PNe_segmentation\\\\data\"\n",
    "## Ejecución en el CESGA Finisterrae III\n",
    "masks_directory = route+\"/masks\"\n",
    "data_directory = route+\"/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import random as rd\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "MinMaxNorm = lambda x: (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "class NebulaeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_path, mask_path, dataframe, rsize = None, transform = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_path = image_path  # Ruta a las imágenes\n",
    "        self.mask_path = mask_path  # Ruta a las máscaras\n",
    "        \n",
    "        # Cargar los nombres de las imágenes y máscaras desde el dataframe\n",
    "        self.data_dict = dataframe.set_index('name').to_dict(orient='index')\n",
    "\n",
    "        # Filtrar las rutas de archivo según los nombres en el dataframe\n",
    "        self.img_files = [os.path.join(self.image_path, files['h']) for files in self.data_dict.values()]\n",
    "        self.mask_files = [os.path.join(self.mask_path, files['mask']) for files in self.data_dict.values()]\n",
    "        self.names = list(self.data_dict.keys())  # Nombres de las imágenes y máscaras\n",
    "                \n",
    "        self.rsize = rsize  # Size to use in default Resize transform\n",
    "        self.transform = transform\n",
    "\n",
    "    # Returns both the image and the mask\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_files[index]\n",
    "        mask_path = self.mask_files[index]\n",
    "        \n",
    "        image = np.flip(fits.getdata(img_path, memmap=False).astype(np.float32), axis=0)\n",
    "        mask = plt.imread(mask_path)\n",
    "        \n",
    "        # Take only the first channel. CHANGE THIS IF WE ARE GOING TO WORK WITH NUMEROUS CHANNELS\n",
    "        if len(mask.shape) > 2:\n",
    "            mask = mask[:,:,0]\n",
    "        if len(image.shape) > 2:\n",
    "            image = image[:,:,0]\n",
    "        \n",
    "        # Apply the defined transformations to both image and mask\n",
    "        if self.transform is not None:\n",
    "            seed = np.random.randint(2147483647) # make a seed with numpy generator \n",
    "            rd.seed(seed) # apply this seed to image transforms\n",
    "            torch.manual_seed(seed)\n",
    "            if type(self.transform) == tuple:\n",
    "                image = self.transform[0](image)\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "            rd.seed(seed) # apply the same seed to mask transforms\n",
    "            torch.manual_seed(seed) \n",
    "            if type(self.transform) == tuple:\n",
    "                mask = self.transform[1](mask)\n",
    "            else:\n",
    "                mask = self.transform(mask)\n",
    "        else:\n",
    "            if self.rsize is not None:\n",
    "                t = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(self.rsize, interpolation= InterpolationMode.NEAREST)\n",
    "                    ])\n",
    "            else:\n",
    "                t = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "            image = t(image)\n",
    "            mask = t(mask)\n",
    "        \n",
    "        return image, mask.int()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def different_shapes(self):\n",
    "        shapes = set([tuple(self[i][0].permute(2,1,0).shape) for i in range(len(self))])\n",
    "        return list(shapes)\n",
    "    \n",
    "    def plot(self, index, plot_image = True, plot_mask = False):\n",
    "        \"\"\"\n",
    "        Muestra una imagen y/o máscara aleatoria del lote.\n",
    "        \n",
    "        Parámetros:\n",
    "        index (int): Índice del lote.\n",
    "        plot_image (bool, opcional): Si es True, muestra la imagen. Por defecto es True.\n",
    "        plot_mask (bool, opcional): Si es True, muestra la máscara. Por defecto es False.\n",
    "        \"\"\"\n",
    "        image, mask = self[index]\n",
    "        image = image.permute(1,2,0)\n",
    "        mask = mask.permute(1,2,0)\n",
    "        name = self.names[index]\n",
    "        \n",
    "        if plot_image:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            fig.suptitle(f\"Canales de la nebulosa {name}\", fontweight = 'bold', fontsize = 14)\n",
    "            ax.imshow(image, cmap = \"gray\")\n",
    "            ax.set_title(f\"Canal H\")\n",
    "            fig.show()\n",
    "        if plot_mask:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            fig.suptitle(f\"Máscara de la nebulosa {name}\", fontweight = 'bold', fontsize = 14)\n",
    "            ax.imshow(mask, cmap = \"gray\")\n",
    "            fig.show()\n",
    "            \n",
    "    def different_shapes(self):\n",
    "        shapes = set([tuple(self[i][0].permute(2,1,0).shape) for i in range(len(self))])\n",
    "        return list(shapes)\n",
    "    \n",
    "    def bg_obj_proportions(self):\n",
    "        proportions = []\n",
    "        for i in range(len(self)):\n",
    "            mask = self[i][1].numpy()\n",
    "            bg = np.sum(mask == 0)\n",
    "            obj = np.sum(mask == 1)\n",
    "            proportions.append(obj/(bg+obj))\n",
    "        return proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora deberíamos de ser capaces de poder cargar todas las imágenes, como tensores de PyTorch, de nuestro csv como un Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot(40, plot_image = True, plot_mask = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Segmentación de las imágenes\n",
    "Para la segmentación de las imágenes, vamos a probar diferentes algoritmos/técnicas propuestas por Diego Cantorna en el notebook de 'astrosegstem', pero para un mayor conjunto de datos para poder evaluarlas y verificar sus resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de resultados\n",
    "Para evaluar el resultado de las técnicas de segmentación se pueden emplear distintas métricas.\n",
    "\n",
    "Algunas de las métricas más utilizadas son la precisión, accuracy y recall, que junto al análisis de la matriz de confusión son las más utilizadas para cualquier problema de procesamiento de imágenes. A estas también se unen:\n",
    "- **Coeficiente de Dice** (Dice Similarity Coefficient): Mide la similitud entre la segmentación predicha y la segmentación de referencia. Valores más cercanos a 1 indican una mejor superposición. Para un problema de segmentación binaria como el nuestro, el F1-Score y el Dice son equivalentes.\n",
    "- **Índice de Jaccard** (Jaccard Index o Intersection over Union, IoU): Calcula la intersección entre la segmentación predicha y la segmentación de referencia dividida por su unión. También mide la superposición.\n",
    "las cuales son métricas básicas y esenciales en los problemas de segmentación.\n",
    "\n",
    "Vamos a utilizar todas estas métricas para evaluar nuestras técnicas de segmentación.\n",
    "\n",
    "Vamos a dar mayor prioridad a la hora de evaluar al F1-Score (equivalente al Dice), al IoU y a la precisión, debido a que queremos extraer la silueta aunque no sea de una manera exacta. Métricas como el accuracy en este tipo de problemas no son muy representativas dado a que si el 90 por ciento de la imagen es fondo y nuestra técnica predice como máscara todo 0s (es decir, todo negro) nos va a devolver un 90 por ciento de accuracy pero realmente no nos estaría aportando ninguna información de valor. El recall sería una métrica más idónea si no nos quisiésemos saltar ningún píxel que tenemos que predecir como positivo, aunque diésemos algún falso positivo (métrica muy observada en segmentación de imagen médica por ejemplo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas de agrupamiento de datos\n",
    "Las técnicas de agrupamiento (clustering) tratan de encontrar una partición de un\n",
    "conjunto de datos de forma que los elementos de un mismo grupo sean más similares\n",
    "que los elementos de grupos distintos. Esto permite resumir un conjunto de datos,\n",
    "y puede facilitar algunos procesos de visualización o análisis posteriores con otras\n",
    "técnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "class ApplyKMeans:\n",
    "    def __init__(self, concat = False, **kwargs):\n",
    "        self.concat = concat\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "            \n",
    "        im_array = im.reshape(-1, 1)\n",
    "    \n",
    "        kmeans = KMeans(**self.kwargs).fit(im_array)  # Entrenar el modelo K-Means\n",
    "        \n",
    "        # Obtener la imagen segmentada aplicando el algoritmo a cada píxel de la imagen\n",
    "        im_segm_array = kmeans.predict(im_array)\n",
    "\n",
    "        # Reemplazar los índices de los clústeres por los centroides de los clústeres\n",
    "        im_segm_array = np.array([kmeans.cluster_centers_[i] for i in im_segm_array])\n",
    "\n",
    "        # Cambiar las dimensiones de los datos segmentados para que se correspondan con la imagen inicial\n",
    "        im_segm = im_segm_array.reshape(im.shape[0], im.shape[1], 1)\n",
    "        \n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            return np.concatenate((im_orig, im_segm), axis=2)\n",
    "        else:\n",
    "            return im_segm\n",
    "        \n",
    "class ApplyMorphology:\n",
    "    def __init__(self, operation = morphology.opening, concat = False, **kwargs):\n",
    "        self.concat = concat\n",
    "        self.operation = operation\n",
    "        self.kwargs = kwargs\n",
    "        if operation == morphology.binary_opening or operation == morphology.binary_closing:\n",
    "            self.mode = \"star_background\"\n",
    "        else:\n",
    "            self.mode = \"nebulae\"\n",
    "    \n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "        \n",
    "        if self.mode == \"nebulae\":\n",
    "            im_filt = self.operation(im, **self.kwargs)\n",
    "        else:\n",
    "            im_preproc = np.copy(im)\n",
    "            im_filt = ndimage.gaussian_filter(im, sigma=3)\n",
    "            im_filt[im == 0] = 0\n",
    "\n",
    "            im_zonas_claras_peq = im > (im_filt + np.std(im))\n",
    "\n",
    "            im_zonas_claras_peq = self.operation(im_zonas_claras_peq, **self.kwargs)\n",
    "                \n",
    "            im_preproc = (im_preproc - np.min(im_preproc))\n",
    "            im_preproc[im_zonas_claras_peq] = 0\n",
    "            \n",
    "            im_filt = im_preproc\n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            im_filt = np.expand_dims(im_filt, axis=2)\n",
    "            return np.concatenate((im_orig, im_filt), axis=2)\n",
    "        else:\n",
    "            return self.operation(im, **self.kwargs)\n",
    "\n",
    "class ApplyIntensityTransformation:\n",
    "    def __init__(self, transformation = exposure.rescale_intensity, concat = False, **kwargs):\n",
    "        self.transformation = transformation\n",
    "        self.kwargs = kwargs\n",
    "        self.concat = concat\n",
    "        self.in_range = None\n",
    "        self.kernel_size = None\n",
    "        \n",
    "        if \"in_range\" in self.kwargs:\n",
    "            self.in_range = self.kwargs[\"in_range\"]\n",
    "        \n",
    "        if \"kernel_size\" in self.kwargs:\n",
    "            self.kernel_size = self.kwargs[\"kernel_size\"]\n",
    "    \n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "        \n",
    "        if self.in_range is not None:\n",
    "            self.kwargs[\"in_range\"] = (im.max() * self.in_range[0], im.max() * self.in_range[1])\n",
    "        \n",
    "        # self.kwargs[\"in_range\"] = (im.min(), im.max()) # Linea para realizar un reescalado de la intensidad de la imagen lineal\n",
    "        \n",
    "        if self.kernel_size is not None:\n",
    "            self.kwargs[\"kernel_size\"] = im.shape[0] // self.kernel_size\n",
    "            \n",
    "        im_trans = self.transformation(im, **self.kwargs)\n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            im_trans = np.expand_dims(im_trans, axis=2)\n",
    "            return np.concatenate((im_orig, im_trans), axis=2)\n",
    "        else:\n",
    "            return self.transformation(im, **self.kwargs)\n",
    "        \n",
    "class ApplyFilter:\n",
    "    def __init__(self, filter = ndimage.gaussian_filter, concat = False, **kwargs):\n",
    "        self.filter = filter\n",
    "        self.kwargs = kwargs\n",
    "        self.concat = concat\n",
    "    \n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "        \n",
    "        im_filt = self.filter(im, **self.kwargs)\n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            im_filt = np.expand_dims(im_filt, axis=2)\n",
    "            return np.concatenate((im_orig, im_filt), axis=2)\n",
    "        else:\n",
    "            return self.filter(im, **self.kwargs)\n",
    "        \n",
    "class CustomPad():\n",
    "    def __init__(self, target_size = (1056, 1536), fill = 0):\n",
    "        self.target_size = target_size\n",
    "        self.fill = fill\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        # Get the size of the input image\n",
    "        width, height = image.shape[2], image.shape[1]\n",
    "\n",
    "        # Compute the size of the padding\n",
    "        pad_width = self.target_size[1] - width\n",
    "        pad_height = self.target_size[0] - height\n",
    "\n",
    "        # Compute the padding\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "\n",
    "        # Apply the padding\n",
    "        return transforms.functional.pad(image, (pad_left, pad_top, pad_right, pad_bottom), fill = self.fill)\n",
    "    \n",
    "    \n",
    "def plot_all(image, mask, **kwargs):\n",
    "        image = image.permute(1,2,0)\n",
    "        mask = mask.permute(1,2,0)\n",
    "        \n",
    "        n_channels = image.shape[2]\n",
    "        fig, ax = plt.subplots(1, n_channels + 1, figsize=(5 * n_channels, 5))\n",
    "        # fig.suptitle(f\"Canales de la nebulosa y máscara\", fontweight = 'bold', fontsize = 14)\n",
    "        for i in range(n_channels):\n",
    "            ax[i].imshow(image[:,:,i]*255, **kwargs)\n",
    "            ax[i].set_title(f\"Canal {i}\")\n",
    "            \n",
    "        ax[n_channels].imshow(mask, cmap = \"gray\")\n",
    "        ax[n_channels].set_title(f\"Máscara\")\n",
    "        fig.show()\n",
    "    \n",
    "def filter_cluster(image, min_background_percentage=0.90):\n",
    "    \"\"\"\n",
    "    Filtra los clusters de una imagen binarizada para obtener el fondo.\n",
    "    \n",
    "    Parámetros:\n",
    "    image (torch.Tensor): Imagen binarizada.\n",
    "    min_background_percentage (float, opcional): Porcentaje mínimo de píxeles de fondo. Por defecto es 0.90.\n",
    "    \n",
    "    Retorna:\n",
    "    torch.Tensor: Imagen binarizada con el fondo.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage:\n",
    "            break\n",
    "        \n",
    "        background = new_background\n",
    "    \n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. K-Means\n",
    "Vamos a comenzar por la técnica más básica (y en la que se basan la mayoría), K-Means.\n",
    "\n",
    "Para aplicar el algoritmo se selecciona el número de grupos a utilizar y un prototipo (elemento representativo) de cada grupo. A continuación se realiza un proceso iterativo en el que se van asignando datos al grupo más próximo, se recalcula el prototipo de cada grupo, y se repite el proceso hasta que se estabiliza. \n",
    "\n",
    "En este caso aplicaremos el algoritmo a los píxeles de imágenes de niveles de gris, por lo que el prototipo de cada grupo será el valor de un píxel. El número de grupos podemos establecerlo manualmente, realizando pruebas con distintos valores. Existen algoritmos más complejos que tratan de automatizar el proceso, pero es interesante familiarizarse inicialmente con las versiones más simples de los algoritmos, para centrar el estudio en los aspectos fundamentales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las pruebas con el K-Means van a ser realizadas con un modelo K-Means para cada imagen (para ambos canales) normalizando los datos entre 0 y 1 y dejandolos con sus valores reales (Demostrado que funciona exactamente igual, solo se realizará con los datos normalizados para que todas las imágenes se muevan en el mismo rango de valores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from sklearn.cluster import KMeans\n",
    "    \n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyKMeans(concat=False, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "dataset.plot(40, plot_image = True, plot_mask = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "rd.seed(42)\n",
    "random_indexs = rd.sample(range(len(dataset)), 3)\n",
    "for index in random_indexs:\n",
    "    plot_all(*dataset[index], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar un filtrado de los cluster de la siguiente manera:\n",
    "1. Tomamos el cluster con el valor de centroide más bajo y lo tomamos como fondo\n",
    "    1. Si el cluster considerado como fondo es demasiado pequeño, nos fijamos en el siguiente cluster con el centroide más bajo\n",
    "    2. Si el siguiente cluster con los valores de centroide más bajo es muy pequeño nos fijamos en el para considerarlo también como fondo. (Esta parte finalmente no le veo mucho sentido implementarlo, debido a que es practicamente lo mismo que variar el umbral general)\n",
    "2. El resto que no se ha considerado como fondo se considera como nebulosa consiguiendo una primera aproximación a la segmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda para observar las proporciones de fondo máximas, mínimas y medias de las imágenes para decidir el umbral de segmentación\n",
    "nebulae_proportions = dataset.bg_obj_proportions()\n",
    "print(f\"Mean background proportion: {1-np.mean(nebulae_proportions):.4f}\\nMax background proportion: {1-min(nebulae_proportions):.4f}\\nMin background proportion: {1-max(nebulae_proportions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda de código donde se realizan algunas pruebas para comprobar los resultados de la segmentación\n",
    "# Más adelante se implementa este código en una función que se puede llamar desde el script principal\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[1]\n",
    "    \n",
    "    min_background_percentage = 0.925\n",
    "    # min_add_background_percentage = 0.2\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "        #     if add_background.sum() / add_background.numel() > min_add_background_percentage:\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         continue\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos una función definida que nos selecciona los primeros clusters convenientes como fondo, vamos a definir una metodología de evaluación y vamos a comprobar que tal funciona nuestra primera aproximación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.93).expand_as(mask)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de K-Means***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.301938 | 0.21419  |\n",
    "| f1        | 0.42291  | 0.256297 |\n",
    "| precision | 0.505177 | 0.333949 |\n",
    "| accuracy  | 0.844327 | 0.128148 |\n",
    "| recall    | 0.587245 | 0.329879 |\n",
    "\n",
    "(NOTA: A medida que aumento el número de clusters, a 9, 11, 13 y 15, obtengo mejores resultados, puede tener algún inconveniente?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar ciertas mejoras como por ejemplo, aplicar operadores morfológicos para tratar de eliminar las estrellas que acaparan demasiada atención de la técnica de agrupamiento de datos, aplicar algún filtro sencillo con el que consigamos una mejor diferenciación entre los clústeres e intentar aplicar alguna técnica de umbralización con la que se escoja de mejor manera el mejor conjunto de clusters para segmentar la nebulosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. AREA OPENING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "imagen = dataset[40][0]\n",
    "plt.imshow(imagen.permute(1,2,0).numpy(), cmap='gray')\n",
    "\n",
    "imagen_opening = morphology.area_opening(imagen.permute(1,2,0)[:,:,0].numpy(), area_threshold=500)\n",
    "# imagen_opening = morphology.remove_small_objects(imagen.permute(1,2,0)[:,:,0].numpy(), min_size=500)\n",
    "plt.imshow(imagen_opening, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.93).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfológicos (opening en área)***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.474498 | 0.251984 |\n",
    "| f1        | 0.600424 | 0.260653 |\n",
    "| precision | 0.661401 | 0.323928 |\n",
    "| accuracy  | 0.865881 | 0.162479 |\n",
    "| recall    | 0.758522 | 0.246124 |\n",
    "\n",
    "Como se puede observar, se consiguen mejores resultados aplicando operadores morfológicos que sin ellos.\n",
    "Parece ser que visualmente al procesar la imagen de la última manera que hemos hecho se concentran los valores de los píxeles en ciertos valores, por lo que vamos a imprimir el histograma de algunas imágenes para ver si esto es cierto y vamos a comprobar que no influya demasiado a la hora de realizar el KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA EJECUTAR ESTA CELDA CORRECTAMENTE HACE FALTA HABER EJECUTADO EL EXPERIMENTO ANTERIOR\n",
    "for i in range(0, 5):\n",
    "    im_op_morf = dataset[i][0].permute(1,2,0).numpy()[:,:,1]\n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(im_op_morf, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(im_op_morf)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "for i in range(0, 5):\n",
    "    im_op_morf = dataset[i][0].permute(1,2,0).numpy()[:,:,1]\n",
    "    # Se podría hacer un reescalado de la intensidad de las imagenes del mínimo al máximo (lineal, simplemente mover el histograma)\n",
    "    # pero haciendo de esta forma conseguimos resaltar las partes de nebulosa respecto de las de fondo\n",
    "    image_reescaled = exposure.rescale_intensity(im_op_morf, in_range = (im_op_morf.max()/5, im_op_morf.max()), out_range = (0, 1))\n",
    "    \n",
    "    # Probamos con un ajuste logarítmico de la intensidad\n",
    "    # image_reescaled = exposure.adjust_log(im_op_morf, gain=1.2, inv=True)\n",
    "    \n",
    "    # También probamos con una ecualización del histograma para que las intensidades estén más repartidas\n",
    "    # image_reescaled = exposure.equalize_hist(im_op_morf)\n",
    "    \n",
    "    # Y por último, probamos con una ecualización adaptativa del histograma\n",
    "    # image_reescaled = exposure.equalize_adapthist(im_op_morf, kernel_size = im_op_morf.shape[0]//10)\n",
    "    \n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(image_reescaled, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(image_reescaled)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.rescale_intensity, concat = True, in_range = (1/5, 1), out_range = (0, 1)),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, kernel_size = 5),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.adjust_log, concat = True, gain = 1.5, inv = True),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.rescale_intensity, concat = True, in_range = (1/5, 1), out_range = (0, 1)),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, kernel_size = 5),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.adjust_log, concat = True, gain = 1.5, inv = True),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.93).expand_as(mask)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfológicos (opening en área) y adaptación del histograma***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.462187 | 0.251906 |\n",
    "| f1        | 0.588433 | 0.261978 |\n",
    "| precision | 0.653917 | 0.331209 |\n",
    "| accuracy  | 0.85844  | 0.166378 |\n",
    "| recall    | 0.753286 | 0.24564  |\n",
    "\n",
    "Como se puede observar, los mejores resultados obtenidos son muy similares (iguales si se hace una adaptación del histograma lineal) a los resultados obtenidos sin la adaptación del histograma (después de hacer el operador morfológico), vamos a probar a continuación a hacer una adaptación del histograma a la imagen original y después hacer los operadores morfológicos y el KMeans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.93).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con adaptación del histograma y operadores morfológicos (opening en área)***\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.482382 | 0.243033  |\n",
    "| f1        | 0.610257 | 0.255888  |\n",
    "| precision | 0.646103 | 0.303263  |\n",
    "| accuracy  | 0.911641 | 0.0766837 |\n",
    "| recall    | 0.747889 | 0.289217  |\n",
    "\n",
    "Como podemos observar, los resultados practicamente iguales que los anteriores aunque, al ver las imágenes me hace sospechar que un filtro como por ejemplo Gaussiano después de la adaptación del histograma podría hacer mejorar los resultados considerablemente. Otra mejora que veo posible es la de incluir el operador morfológico de closing en el resultado final como postprocesado, aunque de este apartado podemos hablar más adelante (dejamos los resultados en la siguiente tabla haciendo una pequeña prueba con esta mejora)\n",
    "\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.514091 | 0.257969 |\n",
    "| f1        | 0.635843 | 0.262296 |\n",
    "| precision | 0.654544 | 0.309503 |\n",
    "| accuracy  | 0.903982 | 0.104944 |\n",
    "| recall    | 0.814793 | 0.249345 |\n",
    "\n",
    "Como última prueba de este apartado vamos a probar a eliminar por completo gracias a los operadores morfológicos el fondo de estrellas de las imágenes, en vez de intentar reducir su visibilidad como estabamos haciendo hasta ahora (gracias a la función area_opening). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. BINARY OPENING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.morphology as morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (8,8))\n",
    "imagen = dataset[1][0].permute(1,2,0).numpy()[:,:,0]\n",
    "imagen_preproc = np.copy(imagen)\n",
    "\n",
    "ax[0].imshow(imagen, cmap='gray')\n",
    "\n",
    "imagen_filt = ndimage.gaussian_filter(imagen, sigma=3)\n",
    "imagen_filt[imagen == 0] = 0\n",
    "\n",
    "imagen_zonas_claras_peq = imagen > (imagen_filt + np.std(imagen))\n",
    "\n",
    "imagen_zonas_claras_peq = morphology.binary_opening(imagen_zonas_claras_peq, morphology.disk(2))\n",
    "    \n",
    "imagen_preproc = (imagen_preproc - np.min(imagen_preproc))\n",
    "imagen_preproc[imagen_zonas_claras_peq] = 0\n",
    "\n",
    "# imagen_opening = morphology.remove_small_objects(imagen.permute(1,2,0)[:,:,0].numpy(), min_size=500)\n",
    "ax[1].imshow(imagen_preproc, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.93).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfólogicos para eliminar el fondo de estrellas (opening binario)***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.340304 | 0.202407 |\n",
    "| f1        | 0.474101 | 0.230723 |\n",
    "| precision | 0.548508 | 0.328343 |\n",
    "| accuracy  | 0.860052 | 0.112781 |\n",
    "| recall    | 0.629009 | 0.295397 |\n",
    "\n",
    "Como podemos comprobar, funciona algo mejor que solo utilizar KMeans aunque bastante parecido, como se puede observar en las imágenes observadas. Vamos a probar a unificar las dos técnicas de operadores morfológicos que hemos aplicado, primero eliminamos el fondo de estrellas y después intentamos visualizar lo menos posible los restos que queden de el (primero binary_opening y después area_opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.94).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con operadores morfológicos (ambas técnicas)***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.472936 | 0.234044 |\n",
    "| f1        | 0.605284 | 0.24067  |\n",
    "| precision | 0.67945  | 0.311074 |\n",
    "| accuracy  | 0.878765 | 0.142001 |\n",
    "| recall    | 0.726142 | 0.241789 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver los resultados son muy parecidos a solo realizar la técnica de operadores morfológicos que NO elimina el fondo de estrellas por completo, aunque hemos tenido que subir un poco el umbral manual (porcentaje de píxeles de fondo) para obtener ese resultado, por lo que vamos a comprobar los resultados que da con una adaptación del histograma entre ambas técnicas de operadores morfológicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 7),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.94).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = morphology.binary_closing(output.permute(1,2,0).numpy()[:,:,0], footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con Opening binario, adaptación del histograma y opening en área***\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.496861 | 0.230796  |\n",
    "| f1        | 0.62982  | 0.227609  |\n",
    "| precision | 0.661146 | 0.282945  |\n",
    "| accuracy  | 0.916543 | 0.0739382 |\n",
    "| recall    | 0.769579 | 0.246387  |\n",
    "\n",
    "Vamos a comprobar finalmente que tal funcionaría con el postprocesado sencillo que probamos anteriormente\n",
    "\n",
    "***Resultados de KMeans con Opening binario, adaptación del histograma y opening en área + postprocesado***\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.534588 | 0.250919  |\n",
    "| f1        | 0.658135 | 0.243586  |\n",
    "| precision | 0.656112 | 0.29426   |\n",
    "| accuracy  | 0.917111 | 0.0781187 |\n",
    "| recall    | 0.841828 | 0.223383  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. FILTRO GAUSSIANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    image = dataset[i][0].permute(1,2,0).numpy()[:,:,0]\n",
    "    \n",
    "    # image_reescaled = exposure.equalize_hist(image, nbins = 640)\n",
    "    \n",
    "    # im_op_morf = morphology.area_opening(image_reescaled, area_threshold=200)\n",
    "    \n",
    "    im_op_morf = morphology.area_opening(image, area_threshold=200)\n",
    "    \n",
    "    imagen_filter = ndimage.gaussian_filter(im_op_morf, sigma = 4)\n",
    "    \n",
    "    \n",
    "    # Se podría hacer un reescalado de la intensidad de las imagenes del mínimo al máximo (lineal, simplemente mover el histograma)\n",
    "    # pero haciendo de esta forma conseguimos resaltar las partes de nebulosa respecto de las de fondo\n",
    "    # image_reescaled = exposure.rescale_intensity(im_op_morf, in_range = (im_op_morf.max()/5, im_op_morf.max()), out_range = (0, 1))\n",
    "    \n",
    "    # Probamos con un ajuste logarítmico de la intensidad\n",
    "    # image_reescaled = exposure.adjust_log(im_op_morf, gain=1.2, inv=True)\n",
    "    \n",
    "    # También probamos con una ecualización del histograma para que las intensidades estén más repartidas\n",
    "    # image_reescaled = exposure.equalize_hist(im_op_morf, nbins = 640)\n",
    "    \n",
    "    # Y por último, probamos con una ecualización adaptativa del histograma\n",
    "    # image_reescaled = exposure.equalize_adapthist(im_op_morf, kernel_size = im_op_morf.shape[0]//10)\n",
    "    \n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(imagen_filter, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(imagen_filter)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.94).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = output.permute(1,2,0).numpy()[:,:,0]\n",
    "    # output = morphology.binary_closing(output, footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Resultados de KMeans con opening en área y Filtro Gaussiano (sigma 5)***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.533148 | 0.247184 |\n",
    "| f1        | 0.65724  | 0.245682 |\n",
    "| precision | 0.732878 | 0.29252  |\n",
    "| accuracy  | 0.901664 | 0.115164 |\n",
    "| recall    | 0.758274 | 0.244278 |\n",
    "\n",
    "***Resultados de KMeans con adaptación del histograma, opening en área y filtro gaussiano***\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.51504  | 0.252026  |\n",
    "| f1        | 0.638368 | 0.258574  |\n",
    "| precision | 0.694062 | 0.30799   |\n",
    "| accuracy  | 0.918851 | 0.0819133 |\n",
    "| recall    | 0.751193 | 0.286227  |\n",
    "\n",
    "***Resultados de KMeans con opening binario, opening en área y Filtro Gaussiano (sigma 5)***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.50307  | 0.227348 |\n",
    "| f1        | 0.636952 | 0.22226  |\n",
    "| precision | 0.701959 | 0.301808 |\n",
    "| accuracy  | 0.903936 | 0.106539 |\n",
    "| recall    | 0.763739 | 0.249194 |\n",
    "\n",
    "***Resultados de KMeans con opening binario, adaptación del histograma, opening en área y Filtro Gaussiano (sigma 5)***\n",
    "|           |     mean |      std |\n",
    "|:----------|---------:|---------:|\n",
    "| iou       | 0.537252 | 0.246508 |\n",
    "| f1        | 0.663492 | 0.228315 |\n",
    "| precision | 0.719191 | 0.298549 |\n",
    "| accuracy  | 0.925891 | 0.073396 |\n",
    "| recall    | 0.776446 | 0.243754 |\n",
    "\n",
    "***Resultados de KMeans con opening binario, adaptación del histograma, opening en área y Filtro Gaussiano (sigma 5) + postprocesado***\n",
    "|           |     mean |       std |\n",
    "|:----------|---------:|----------:|\n",
    "| iou       | 0.544275 | 0.244476  |\n",
    "| f1        | 0.670401 | 0.224853  |\n",
    "| precision | 0.728293 | 0.294329  |\n",
    "| accuracy  | 0.927701 | 0.0734514 |\n",
    "| recall    | 0.777289 | 0.24409   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4. UMBRALIZACIÓN (para evitar tener que elegir un umbral en el porcentaje de píxeles de fondo)\n",
    "(IGNORAR DE MOMENTO, NECESITA REFLEXIÓN Y DESARROLLO - 14/06/24)\n",
    "\n",
    "Necesitamos algún método, como por ejemplo un test estadístico, que nos ayude a que la división de clusters en fondo y nebulosa sea más personalizada para cada imagen de lo que es un umbral de porcentaje de píxeles de fondo.\n",
    "\n",
    "Algunas ideas que se me han ocurrido han sido:\n",
    "- Aplicar algún método, como Otsu, donde se considera cada cluster como una clase y se busca la división de los datos (a través de un umbral) que minimize la varianza intra-clase.\n",
    "\n",
    "- Intentar modelar los clúster como una Mixtura de Gaussianas (GMM, por sus siglas en inglés Gaussian Mixture Model) de dos Gaussianas (o más, pero por simplicidad y para empezar solo con 2)\n",
    "\n",
    "(NOTA: Aunque utilicemos otros métodos para separar los clústers en fondo y nebulosa, podemos seguir utilizando el umbral del porcentaje manual para descartar los primeros clústeres que van a ser la mayoría de veces solo fondo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    imagen = dataset[i][0].permute(1,2,0).numpy()[:,:,0]\n",
    "    imagen = exposure.equalize_hist(imagen, nbins = 1024)\n",
    "    fig, axis = plt.subplots(1,2, figsize = (8,8))\n",
    "    axis[0].imshow(imagen, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen (op. morf.)\")\n",
    "    axis[1].hist(imagen)\n",
    "    axis[1].set_title(\"Histograma de la imagen (op. morf.)\")\n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Método de Otsu (simple)\n",
    "Vamos a comenzar aplicando al KMeans una umbralización de Otsu, tanto de manera general como local, para comprobar si consigue separar los clusters del KMeans en fondo y nebulosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    # ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "rd.seed(42)\n",
    "random_indexs = rd.sample(range(len(dataset)), 3)\n",
    "for index in random_indexs:\n",
    "    plot_all(*dataset[index], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image_knn = image_original[-1]\n",
    "    \n",
    "    image = filter_cluster(image_knn, min_background_percentage = 0.8).expand_as(mask).permute(1,2,0).numpy()[:,:,0]\n",
    "    \n",
    "    image = image * image_knn.numpy()\n",
    "    # Calculamos el histograma de image y lo recortamos desde el minimo distinto de 0 al maximo\n",
    "    image_thr = image[image != 0]\n",
    "    # image_thr = threshold_local(image_thr)[0]\n",
    "    \n",
    "    image_thr = threshold_otsu(image_thr)\n",
    "    \n",
    "    fig, axis = plt.subplots(1,2, figsize = (12,8))\n",
    "    \n",
    "    axis[0].imshow(image, cmap='gray')\n",
    "    axis[0].set_title(\"Imagen en escala de grises\")\n",
    "    axis[1].hist(image)\n",
    "    axis[1].set_title(\"Histograma de la imagen\")\n",
    "    \n",
    "    axis[1].axvline(image_thr, color='r')\n",
    "    \n",
    "    fig.suptitle(f\"Imagen {i}\", fontsize=16, fontweight = 'bold')\n",
    "    fig.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(image > image_thr, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "    # min_add_background_percentage = 0.2\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "        #     if add_background.sum() / add_background.numel() > min_add_background_percentage:\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         continue\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.94).expand_as(mask)\n",
    "    output = output.permute(1,2,0).numpy()[:,:,0]\n",
    "    output = morphology.binary_closing(output, footprint=morphology.disk(5))\n",
    "    output = morphology.remove_small_objects(output, min_size=500)\n",
    "    output = torch.tensor(output).unsqueeze(0)\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy C-Means (FCM)\n",
    "Vamos a continuar probando una de las variantes del algoritmo de KMeans. Este algoritmo se diferencia del anterior en que, en vez de aportar un cluster al que pertenece cada cluster, aporta un nivel de pertenencia entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz\n",
    "im, mask = dataset[0]\n",
    "\n",
    "im_orig = im[:,:,0].numpy().copy()\n",
    "if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "    im = im[:,:,-1]\n",
    "    \n",
    "im_array = im.reshape(-1, 1)\n",
    "\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data=im_array, c=7, m=2, error = 0.005, maxiter=10, seed=42)  # Aplicar el algoritmo FCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_array = np.argmax(u, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([980, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz\n",
    "\n",
    "class ApplyFCM:\n",
    "    def __init__(self, concat = False, **kwargs):\n",
    "        self.concat = concat\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, im):\n",
    "        im_orig = im.copy()\n",
    "        if len(im.shape) == 3 and im.shape[2] > 1:\n",
    "            im = im[:,:,-1]\n",
    "            \n",
    "        im_array = im.reshape(-1, 1)\n",
    "\n",
    "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(data=im_array, **self.kwargs)  # Aplicar el algoritmo FCM\n",
    "        \n",
    "        # Asociar a cada píxel el cluster para el que tiene una mayor pertenencia\n",
    "        clusters_array = np.argmax(u, axis=0)\n",
    "        # maximos = np.max(u, axis=0)\n",
    "\n",
    "        # Reemplazar los índices de los clústeres por los centroides de los clústeres\n",
    "        im_segm_array = np.array([cntr[i] for i in clusters_array])\n",
    "\n",
    "        # Cambiar las dimensiones de los datos segmentados para que se correspondan con la imagen inicial\n",
    "        im_segm = im_segm_array.reshape(im.shape[0], im.shape[1], 1)\n",
    "        \n",
    "        if self.concat:\n",
    "            if len(im_orig.shape) < 3:\n",
    "                im_orig = np.expand_dims(im_orig, axis=2)\n",
    "                \n",
    "            return np.concatenate((im_orig, im_segm), axis=2)\n",
    "        else:\n",
    "            return im_segm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m unique_values \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39munique(\u001b[38;5;28msorted\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m background \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(image \u001b[38;5;241m==\u001b[39m unique_values[\u001b[38;5;241m0\u001b[39m], torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 35\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/pyplot.py:1599\u001b[0m, in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;124;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m \n\u001b[1;32m   1597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m fig \u001b[38;5;241m=\u001b[39m figure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw)\n\u001b[0;32m-> 1599\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/figure.py:931\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m    928\u001b[0m     gridspec_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m width_ratios\n\u001b[1;32m    930\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gridspec(nrows, ncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgridspec_kw)\n\u001b[0;32m--> 931\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/gridspec.py:298\u001b[0m, in \u001b[0;36mGridSpecBase.subplots\u001b[0;34m(self, sharex, sharey, squeeze, subplot_kw)\u001b[0m\n\u001b[1;32m    296\u001b[0m         subplot_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m shared_with[sharex]\n\u001b[1;32m    297\u001b[0m         subplot_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharey\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m shared_with[sharey]\n\u001b[0;32m--> 298\u001b[0m         axarr[row, col] \u001b[38;5;241m=\u001b[39m \u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_subplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# turn off redundant tick labeling\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sharex \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/figure.py:782\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m    781\u001b[0m     projection_class, pkw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 782\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43mprojection_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     key \u001b[38;5;241m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/axes/_base.py:678\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[0;34m(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_axisbelow(mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.axisbelow\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rasterization_zorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# funcs used to format x and y - fall back on major formatters\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt_xdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/axes/_base.py:1388\u001b[0m, in \u001b[0;36m_AxesBase.clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcla()\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/axes/_base.py:1356\u001b[0m, in \u001b[0;36m_AxesBase.__clear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_axis_on()\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m-> 1356\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sharex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_visible(xaxis_visible)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/axis.py:1112\u001b[0m, in \u001b[0;36mAxis.set_clip_path\u001b[0;34m(self, path, transform)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_clip_path(path, transform)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminorTicks:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/axis.py:240\u001b[0m, in \u001b[0;36mTick.set_clip_path\u001b[0;34m(self, path, transform)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;129m@_api\u001b[39m\u001b[38;5;241m.\u001b[39mrename_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclippath\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_clip_path\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgridline\u001b[38;5;241m.\u001b[39mset_clip_path(path, transform)\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/artist.py:803\u001b[0m, in \u001b[0;36mArtist.set_clip_path\u001b[0;34m(self, path, transform)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, Rectangle):\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclipbox \u001b[38;5;241m=\u001b[39m TransformedBbox(Bbox\u001b[38;5;241m.\u001b[39munit(),\n\u001b[0;32m--> 803\u001b[0m                                        \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clippath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    805\u001b[0m         success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/patches.py:261\u001b[0m, in \u001b[0;36mPatch.get_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the `~.transforms.Transform` applied to the `Patch`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_patch_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43martist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArtist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/transforms.py:1347\u001b[0m, in \u001b[0;36mTransform.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03m    Compose two transforms together so that *self* is followed by *other*.\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \n\u001b[1;32m   1344\u001b[0m \u001b[38;5;124;03m    ``A + B`` returns a transform ``C`` so that\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;124;03m    ``C.transform(x) == B.transform(A.transform(x))``.\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mcomposite_transform_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Transform) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m             \u001b[38;5;28mNotImplemented\u001b[39m)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/transforms.py:2522\u001b[0m, in \u001b[0;36mcomposite_transform_factory\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, Affine2D) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Affine2D):\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CompositeAffine2D(a, b)\n\u001b[0;32m-> 2522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCompositeGenericTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/transforms.py:2366\u001b[0m, in \u001b[0;36mCompositeGenericTransform.__init__\u001b[0;34m(self, a, b, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b \u001b[38;5;241m=\u001b[39m b\n\u001b[0;32m-> 2366\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/transforms.py:197\u001b[0m, in \u001b[0;36mTransformNode.set_children\u001b[0;34m(self, *children)\u001b[0m\n\u001b[1;32m    192\u001b[0m id_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Use weak references so this dictionary won't keep obsolete nodes\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# alive; the callback deletes the dictionary entry. This is a\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# performance improvement over using WeakValueDictionary.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     ref \u001b[38;5;241m=\u001b[39m \u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_self\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     child\u001b[38;5;241m.\u001b[39m_parents[id_self] \u001b[38;5;241m=\u001b[39m ref\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x1471ea65bf40> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 50839200x1000 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/pyplot.py:197\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_draw_all_if_interactive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mis_interactive():\n\u001b[0;32m--> 197\u001b[0m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backend_bases.py:1893\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 1893\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:383\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:398\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:70\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[0;34m(self, width, height, dpi)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[0;31mValueError\u001b[0m: Image size of 50839200x1000 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 50839200x1000 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backend_bases.py:2150\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m layout_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mget_layout_engine()\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout_engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2147\u001b[0m     \u001b[38;5;66;03m# we need to trigger a draw before printing to make sure\u001b[39;00m\n\u001b[1;32m   2148\u001b[0m     \u001b[38;5;66;03m# CL works.  \"tight\" also needs a draw to get the right\u001b[39;00m\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;66;03m# locations:\u001b[39;00m\n\u001b[0;32m-> 2150\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_renderer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprint_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2155\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[1;32m   2156\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backend_bases.py:1642\u001b[0m, in \u001b[0;36m_get_renderer\u001b[0;34m(figure, print_method)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   1640\u001b[0m         figure\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39m_switch_canvas_and_return_print_method(fmt))\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1642\u001b[0m     \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Done \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1644\u001b[0m     renderer, \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    447\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    448\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:383\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:398\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/co/ela/conda/envs/TFG_env/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:70\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[0;34m(self, width, height, dpi)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[0;31mValueError\u001b[0m: Image size of 50839200x1000 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 5.08392e+07x1000 with 2934 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELDA PARA MOSTRAR LA SEGMENTACIÓN PASO A PASO Y LAS TRANSFORMACIONES APLICADAS (Ejecutar si se quiere observar el proceso paso a paso)\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    # ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    # ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyFCM(concat=True, c=7, m=2, error = 0.005, maxiter=10, seed=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(0,5):\n",
    "    image_original, mask = dataset[i]\n",
    "    image = image_original[-1]\n",
    "    \n",
    "    min_background_percentage = 0.93\n",
    "\n",
    "    # Sort unique cluster values in ascending order\n",
    "    unique_values = image.unique(sorted=True)\n",
    "\n",
    "    background = torch.where(image == unique_values[0], torch.tensor(0), torch.tensor(1))\n",
    "\n",
    "    fig, ax = plt.subplots(2, (len(unique_values)-1)//2 + (len(unique_values)-1)%2, figsize=(5 * (len(unique_values)-1)//2, 5 * 2))\n",
    "    cnt = 0\n",
    "    solution = False\n",
    "    \n",
    "    # Mientras que el porcentaje de píxeles de fondo sea menor que el porcentaje mínimo, seguimos añadiendo clusters al fondo\n",
    "    for cluster_value in unique_values[1:]:\n",
    "        j, i = divmod(cnt, 2)\n",
    "        ax[i, j].set_title(f\"Background percentage: {(1 - background.sum() / background.numel())*100:.2f}%\", fontsize = 9)\n",
    "        ax[i, j].imshow(background, cmap = \"gray\")\n",
    "        fig.show()\n",
    "        \n",
    "        add_background = torch.where(image == cluster_value, torch.tensor(0), torch.tensor(1))\n",
    "        new_background = background * add_background\n",
    "        \n",
    "        if (1 - new_background.sum() / new_background.numel()) > min_background_percentage and not solution:\n",
    "            final_background = background.clone()\n",
    "            solution = True\n",
    "\n",
    "        background = new_background\n",
    "        \n",
    "        cnt += 1\n",
    "    \n",
    "    # final_background = morphology.binary_closing(final_background, footprint=morphology.disk(5))\n",
    "    # final_background = morphology.remove_small_objects(final_background, min_size=500)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(final_background, cmap = \"gray\")\n",
    "    plt.title(f\"Segmentation\")\n",
    "    plt.show()\n",
    "    \n",
    "    plot_all(image_original, mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pandas as pd\n",
    "\n",
    "results = {\"iou\": [], \"f1\": [], \"precision\": [], \"accuracy\": [], \"recall\": []}\n",
    "\n",
    "transform_x = transforms.Compose([\n",
    "                    MinMaxNorm,\n",
    "                    ApplyMorphology(operation = morphology.binary_opening, concat = True, footprint = morphology.disk(2)),\n",
    "                    # ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyIntensityTransformation(transformation = exposure.equalize_hist, concat = True, nbins = 640),\n",
    "                    # ApplyIntensityTransformation(transformation = exposure.equalize_adapthist, concat = True, nbins = 640, kernel_size = 5),\n",
    "                    ApplyMorphology(operation = morphology.area_opening, concat = True, area_threshold = 200, connectivity = 1),\n",
    "                    ApplyFilter(filter = ndimage.gaussian_filter, concat = True, sigma = 5),\n",
    "                    ApplyKMeans(concat=True, n_clusters=7, max_iter=10, n_init=10, random_state=42),\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = -1)\n",
    "                    ])\n",
    "\n",
    "transform_y = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # CustomPad(target_size = (980, 980), fill = 0)\n",
    "                    ])\n",
    "\n",
    "df = pd.read_csv(\"data_files_1c.csv\")\n",
    "# Prueba normalizando los datos entre 0 y 1\n",
    "dataset = NebulaeDataset(data_directory, masks_directory, df, transform = (transform_x, transform_y))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    image, mask = dataset[i]\n",
    "    image_knn = image[-1]\n",
    "    \n",
    "    output = filter_cluster(image_knn, min_background_percentage = 0.94).expand_as(mask)\n",
    "    \n",
    "    ## Descomentar para hacer un preprocesado sencillo a las imágenes\n",
    "    # output = output.permute(1,2,0).numpy()[:,:,0]\n",
    "    # output = morphology.binary_closing(output, footprint=morphology.disk(5))\n",
    "    # output = morphology.remove_small_objects(output, min_size=500)\n",
    "    # output = torch.tensor(output).unsqueeze(0)\n",
    "    \n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(output, mask, mode='binary')\n",
    "    \n",
    "    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")        # Índice de Jaccard\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")          # F1-Score\n",
    "    accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")          # Accuracy\n",
    "    recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\")    # Sensibilidad\n",
    "    precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")        # Precisión\n",
    "\n",
    "    results[\"iou\"].append(iou_score)\n",
    "    results[\"f1\"].append(f1_score)\n",
    "    results[\"precision\"].append(precision)\n",
    "    results[\"accuracy\"].append(accuracy)\n",
    "    results[\"recall\"].append(recall)\n",
    "    \n",
    "    ## Si descomentamos las siguientes líneas, se mostrarán varias imágenes segmentadas al igual que en la anterior celda de código\n",
    "    # plot_all(image, mask, cmap = \"gray\")\n",
    "    # plt.figure()\n",
    "    # plt.imshow(output[0], cmap = \"gray\")\n",
    "    # plt.title(f\"Segmentation\")\n",
    "    # plt.show()\n",
    "    # if i == 5:\n",
    "    #     break \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.astype(float).describe().loc[['mean', 'std']].transpose().to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
